{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 세 번째 모델링 : 근로기간의 모든 값을 0~11로 대치 후 모델링\n",
    "\n",
    "근로기간|값\n",
    "-|-\n",
    "< 1 year|0\n",
    "1 year|1\n",
    "2 years|2\n",
    "3 years|3\n",
    "4 years|4\n",
    "5 years|5\n",
    "6 years|6\n",
    "7 years|7\n",
    "8 years|8\n",
    "9 years|9\n",
    "10+ years|10\n",
    "Unknown|11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('train.csv')\n",
    "train = train_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['주택소유상태'] != 'ANY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "대출기간\n",
       "3    64478\n",
       "5    31815\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = dict({\n",
    "    ' 36 months' : 3,\n",
    "    ' 60 months' : 5\n",
    "})\n",
    "\n",
    "train['대출기간'] = train['대출기간'].replace(val)\n",
    "\n",
    "train['대출기간'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['근로기간'] = train['근로기간'].apply(lambda x: '< 1 year' if '<1 year' in x else x)\n",
    "train['근로기간'] = train['근로기간'].apply(lambda x: '1 year' if '1 years' in x else x)\n",
    "train['근로기간'] = train['근로기간'].apply(lambda x: '3 years' if '3' in x else x)\n",
    "train['근로기간'] = train['근로기간'].apply(lambda x: '10+ years' if '10+years' in x else x)\n",
    "\n",
    "duration=dict({'10+ years':10,\n",
    " '9 years':9,\n",
    " '8 years':8,\n",
    " '7 years':7,\n",
    " '6 years':6,\n",
    " '5 years':5,\n",
    " '4 years':4,\n",
    " '3 years':3,\n",
    " '2 years':2,\n",
    " '1 year':1,\n",
    " '< 1 year':0,\n",
    " 'Unknown' : 11})\n",
    "\n",
    "train['근로기간'] = train['근로기간'].replace(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "train['주택소유상태'] = le.fit_transform(train['주택소유상태'])\n",
    "train['대출목적'] = le.fit_transform(train['대출목적'])\n",
    "train['대출등급'] = le.fit_transform(train['대출등급'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>대출금액</th>\n",
       "      <th>대출기간</th>\n",
       "      <th>근로기간</th>\n",
       "      <th>주택소유상태</th>\n",
       "      <th>연간소득</th>\n",
       "      <th>부채_대비_소득_비율</th>\n",
       "      <th>총계좌수</th>\n",
       "      <th>대출목적</th>\n",
       "      <th>최근_2년간_연체_횟수</th>\n",
       "      <th>총상환원금</th>\n",
       "      <th>총상환이자</th>\n",
       "      <th>총연체금액</th>\n",
       "      <th>연체계좌수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12480000</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>72000000</td>\n",
       "      <td>18.90</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14400000</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>130800000</td>\n",
       "      <td>22.33</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>373572</td>\n",
       "      <td>234060.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12000000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>96000000</td>\n",
       "      <td>8.60</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>928644</td>\n",
       "      <td>151944.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14400000</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>132000000</td>\n",
       "      <td>15.09</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>325824</td>\n",
       "      <td>153108.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18000000</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>71736000</td>\n",
       "      <td>25.39</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>228540</td>\n",
       "      <td>148956.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       대출금액  대출기간  근로기간  주택소유상태       연간소득  부채_대비_소득_비율  총계좌수  대출목적  \\\n",
       "0  12480000     3     6       2   72000000        18.90    15     1   \n",
       "1  14400000     5    10       0  130800000        22.33    21    10   \n",
       "2  12000000     3     5       0   96000000         8.60    14     1   \n",
       "3  14400000     3     8       0  132000000        15.09    15     1   \n",
       "4  18000000     5    11       2   71736000        25.39    19     8   \n",
       "\n",
       "   최근_2년간_연체_횟수   총상환원금     총상환이자  총연체금액  연체계좌수  \n",
       "0             0       0       0.0    0.0    0.0  \n",
       "1             0  373572  234060.0    0.0    0.0  \n",
       "2             0  928644  151944.0    0.0    0.0  \n",
       "3             0  325824  153108.0    0.0    0.0  \n",
       "4             0  228540  148956.0    0.0    0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop(['대출등급'], axis=1)\n",
    "y = train['대출등급']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_ss = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_ss, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model, params, random=False):\n",
    "    clf = model\n",
    "    if not random:\n",
    "        grid = GridSearchCV(clf, params,\n",
    "                                scoring='f1_macro', cv=5,\n",
    "                                n_jobs=-1)\n",
    "    else:\n",
    "        grid = RandomizedSearchCV(clf, params, n_iter=10,\n",
    "                                scoring='f1_macro', cv=5,\n",
    "                                n_jobs=-1, random_state=42)\n",
    "        \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    best_params = grid.best_params_\n",
    "    print(\"최상의 매개변수:\", best_params)\n",
    "    \n",
    "    best_score = grid.best_score_\n",
    "    print(\"훈련 점수: {:.3f}\".format(best_score))\n",
    "    \n",
    "    y_pred = best_model.predict(X_val)\n",
    "    macro_f1_val = f1_score(y_val, y_pred, average='macro')\n",
    "    print('테스트 세트 점수: {:.3f}'.format(macro_f1_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'min_samples_leaf': 19, 'min_impurity_decrease': 0.0, 'max_features': 0.68, 'max_depth': 17, 'class_weight': None}\n",
      "훈련 점수: 0.677\n",
      "테스트 세트 점수: 0.666\n"
     ]
    }
   ],
   "source": [
    "params = {'min_samples_leaf':[18,19,20,21,22],\n",
    "          'min_impurity_decrease':[0.0],\n",
    "          'max_features':['auto',0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.69,0.70],\n",
    "          'max_depth':[None,11,12,13,14,15,16,17,18],\n",
    "          'class_weight' : [None, 'balanced']}\n",
    "\n",
    "grid_search(DecisionTreeClassifier(random_state=42), params, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'n_estimators': 730, 'min_samples_leaf': 20, 'min_impurity_decrease': 0, 'max_features': 0.65, 'max_depth': 90}\n",
      "훈련 점수: 0.685\n",
      "테스트 세트 점수: 0.702\n"
     ]
    }
   ],
   "source": [
    "params = {'min_samples_leaf':[20],\n",
    "          'min_impurity_decrease':[0],\n",
    "          'max_features':[0.65,0.6,0.55],\n",
    "          'max_depth':[85,90,95],\n",
    "          'n_estimators' : [730,750,770]}\n",
    "\n",
    "grid_search(RandomForestClassifier(n_jobs=-1, random_state=42), params, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'objective': 'multi:softmax', 'n_estimators': 170, 'max_depth': 34, 'learning_rate': 0.22}\n",
      "훈련 점수: 0.793\n",
      "테스트 세트 점수: 0.794\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators' : [130,150,170],\n",
    "          'learning_rate' : [0.18,0.2,0.22],\n",
    "          'max_depth' : [33,34,35,36,37],\n",
    "          'objective' : ['multi:softmax']}\n",
    "\n",
    "grid_search(XGBClassifier(random_state=42, n_jobs=-1), params, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1457\n",
      "[LightGBM] [Info] Number of data points in the train set: 67405, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747717\n",
      "[LightGBM] [Info] Start training from score -1.206424\n",
      "[LightGBM] [Info] Start training from score -1.248802\n",
      "[LightGBM] [Info] Start training from score -1.975557\n",
      "[LightGBM] [Info] Start training from score -2.572111\n",
      "[LightGBM] [Info] Start training from score -3.897369\n",
      "[LightGBM] [Info] Start training from score -5.434895\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "최상의 매개변수: {'num_leaves': 43, 'n_estimators': 340, 'max_depth': 11, 'learning_rate': 0.09}\n",
      "훈련 점수: 0.787\n",
      "테스트 세트 점수: 0.794\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators' : [340,350,360],\n",
    "          'learning_rate' : [0.05,0.06,0.07,0.08,0.09],\n",
    "          'max_depth' : [8,9,10,11,12],\n",
    "          'num_leaves' : [43,45,47]}\n",
    "\n",
    "grid_search(LGBMClassifier(objective='multiclass', random_state=42, n_jobs=-1), params, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ss = pd.DataFrame(X_ss, columns=X.columns)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "f1_macro_scores = []\n",
    "\n",
    "def skf_score(model):\n",
    "    for train_idx, valid_idx in skf.split(X_ss, y):\n",
    "        X_train = X_ss.iloc[train_idx]\n",
    "        X_val = y.iloc[train_idx]\n",
    "\n",
    "        y_train = X_ss.iloc[valid_idx]\n",
    "        y_val = y.iloc[valid_idx]\n",
    "\n",
    "        model.fit(X_train, X_val)\n",
    "\n",
    "        pred = model.predict(y_train)\n",
    "\n",
    "        f1_macro = f1_score(y_val, pred, average='macro')\n",
    "        f1_macro_scores.append(f1_macro)\n",
    "    \n",
    "    average_f1_macro = np.mean(f1_macro_scores)\n",
    "\n",
    "    print(\"Average F1-macro score:\", average_f1_macro)\n",
    "    try:\n",
    "        if model.feature_importances_.any():\n",
    "            feature_importances = model.feature_importances_\n",
    "            print(\"\\n\",'-'*10,'특성중요도','-'*10)\n",
    "            for feature, importance in zip(X_ss.columns, feature_importances):\n",
    "                print(f\"{feature}: {importance}\")\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-macro score: 0.7010763737633329\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "대출금액: 0.07002911851969708\n",
      "대출기간: 0.03529504123307088\n",
      "근로기간: 0.002055386402501382\n",
      "주택소유상태: 0.0012106893667268236\n",
      "연간소득: 0.010836897382718041\n",
      "부채_대비_소득_비율: 0.015174850697332296\n",
      "총계좌수: 0.0042522523421826205\n",
      "대출목적: 0.0020056258950848444\n",
      "최근_2년간_연체_횟수: 0.0005408129480661561\n",
      "총상환원금: 0.5019585673877407\n",
      "총상환이자: 0.35664075782487914\n",
      "총연체금액: 0.0\n",
      "연체계좌수: 0.0\n"
     ]
    }
   ],
   "source": [
    "skf_score(DecisionTreeClassifier(min_samples_leaf=18, min_impurity_decrease=0, max_features=0.65,\n",
    "                                 max_depth=None, class_weight=None, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-macro score: 0.7337106491739855\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "대출금액: 0.05095479784400546\n",
      "대출기간: 0.045537395660334774\n",
      "근로기간: 0.0028482726556627327\n",
      "주택소유상태: 0.0015965295833664122\n",
      "연간소득: 0.01777375572126978\n",
      "부채_대비_소득_비율: 0.011142237162281757\n",
      "총계좌수: 0.0053632482242000614\n",
      "대출목적: 0.004074013377095862\n",
      "최근_2년간_연체_횟수: 0.0012883103737419248\n",
      "총상환원금: 0.45381591399719595\n",
      "총상환이자: 0.40560552540084527\n",
      "총연체금액: 0.0\n",
      "연체계좌수: 0.0\n"
     ]
    }
   ],
   "source": [
    "skf_score(RandomForestClassifier(n_estimators=730, min_samples_leaf=20, min_impurity_decrease=0, \n",
    "                                 max_features=0.65, max_depth=90, random_state=42, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-macro score: 0.7697288586617749\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "대출금액: 0.030072171241044998\n",
      "대출기간: 0.5025891065597534\n",
      "근로기간: 0.013120010495185852\n",
      "주택소유상태: 0.012862917967140675\n",
      "연간소득: 0.019176431000232697\n",
      "부채_대비_소득_비율: 0.01340008620172739\n",
      "총계좌수: 0.01359183806926012\n",
      "대출목적: 0.018117578700184822\n",
      "최근_2년간_연체_횟수: 0.01852087490260601\n",
      "총상환원금: 0.15769290924072266\n",
      "총상환이자: 0.17012466490268707\n",
      "총연체금액: 0.016124052926898003\n",
      "연체계좌수: 0.014607292599976063\n"
     ]
    }
   ],
   "source": [
    "skf_score(XGBClassifier(objective='multi:softmax', n_estimators=170, max_depth=34, \n",
    "          learning_rate=0.22, n_jobs=-1, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1463\n",
      "[LightGBM] [Info] Number of data points in the train set: 86663, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747730\n",
      "[LightGBM] [Info] Start training from score -1.206395\n",
      "[LightGBM] [Info] Start training from score -1.248807\n",
      "[LightGBM] [Info] Start training from score -1.975538\n",
      "[LightGBM] [Info] Start training from score -2.572234\n",
      "[LightGBM] [Info] Start training from score -3.897282\n",
      "[LightGBM] [Info] Start training from score -5.434888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1470\n",
      "[LightGBM] [Info] Number of data points in the train set: 86663, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747663\n",
      "[LightGBM] [Info] Start training from score -1.206395\n",
      "[LightGBM] [Info] Start training from score -1.248807\n",
      "[LightGBM] [Info] Start training from score -1.975622\n",
      "[LightGBM] [Info] Start training from score -2.572234\n",
      "[LightGBM] [Info] Start training from score -3.897282\n",
      "[LightGBM] [Info] Start training from score -5.434888\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1467\n",
      "[LightGBM] [Info] Number of data points in the train set: 86663, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747663\n",
      "[LightGBM] [Info] Start training from score -1.206434\n",
      "[LightGBM] [Info] Start training from score -1.248767\n",
      "[LightGBM] [Info] Start training from score -1.975622\n",
      "[LightGBM] [Info] Start training from score -2.572234\n",
      "[LightGBM] [Info] Start training from score -3.897282\n",
      "[LightGBM] [Info] Start training from score -5.434888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 86664, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747675\n",
      "[LightGBM] [Info] Start training from score -1.206445\n",
      "[LightGBM] [Info] Start training from score -1.248778\n",
      "[LightGBM] [Info] Start training from score -1.975633\n",
      "[LightGBM] [Info] Start training from score -2.572094\n",
      "[LightGBM] [Info] Start training from score -3.897293\n",
      "[LightGBM] [Info] Start training from score -5.434900\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 86664, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747675\n",
      "[LightGBM] [Info] Start training from score -1.206445\n",
      "[LightGBM] [Info] Start training from score -1.248778\n",
      "[LightGBM] [Info] Start training from score -1.975633\n",
      "[LightGBM] [Info] Start training from score -2.572094\n",
      "[LightGBM] [Info] Start training from score -3.897293\n",
      "[LightGBM] [Info] Start training from score -5.434900\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1467\n",
      "[LightGBM] [Info] Number of data points in the train set: 86664, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747675\n",
      "[LightGBM] [Info] Start training from score -1.206445\n",
      "[LightGBM] [Info] Start training from score -1.248778\n",
      "[LightGBM] [Info] Start training from score -1.975550\n",
      "[LightGBM] [Info] Start training from score -2.572094\n",
      "[LightGBM] [Info] Start training from score -3.897862\n",
      "[LightGBM] [Info] Start training from score -5.434900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004008 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1465\n",
      "[LightGBM] [Info] Number of data points in the train set: 86664, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747675\n",
      "[LightGBM] [Info] Start training from score -1.206445\n",
      "[LightGBM] [Info] Start training from score -1.248778\n",
      "[LightGBM] [Info] Start training from score -1.975550\n",
      "[LightGBM] [Info] Start training from score -2.572094\n",
      "[LightGBM] [Info] Start training from score -3.897862\n",
      "[LightGBM] [Info] Start training from score -5.434900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 86664, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747675\n",
      "[LightGBM] [Info] Start training from score -1.206445\n",
      "[LightGBM] [Info] Start training from score -1.248778\n",
      "[LightGBM] [Info] Start training from score -1.975550\n",
      "[LightGBM] [Info] Start training from score -2.572094\n",
      "[LightGBM] [Info] Start training from score -3.897862\n",
      "[LightGBM] [Info] Start training from score -5.434900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1467\n",
      "[LightGBM] [Info] Number of data points in the train set: 86664, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747675\n",
      "[LightGBM] [Info] Start training from score -1.206445\n",
      "[LightGBM] [Info] Start training from score -1.248778\n",
      "[LightGBM] [Info] Start training from score -1.975550\n",
      "[LightGBM] [Info] Start training from score -2.572094\n",
      "[LightGBM] [Info] Start training from score -3.897862\n",
      "[LightGBM] [Info] Start training from score -5.434900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 86664, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747741\n",
      "[LightGBM] [Info] Start training from score -1.206407\n",
      "[LightGBM] [Info] Start training from score -1.248778\n",
      "[LightGBM] [Info] Start training from score -1.975550\n",
      "[LightGBM] [Info] Start training from score -2.572245\n",
      "[LightGBM] [Info] Start training from score -3.897293\n",
      "[LightGBM] [Info] Start training from score -5.434900\n",
      "Average F1-macro score: 0.7796600062893523\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "대출금액: 15307\n",
      "대출기간: 2357\n",
      "근로기간: 4364\n",
      "주택소유상태: 1491\n",
      "연간소득: 9698\n",
      "부채_대비_소득_비율: 10757\n",
      "총계좌수: 8269\n",
      "대출목적: 2755\n",
      "최근_2년간_연체_횟수: 1444\n",
      "총상환원금: 23119\n",
      "총상환이자: 19817\n",
      "총연체금액: 501\n",
      "연체계좌수: 81\n"
     ]
    }
   ],
   "source": [
    "skf_score(LGBMClassifier(objective='multiclass', num_leaves=43, n_estimators=340, max_depth=11, \n",
    "               learning_rate=0.09, n_jobs=-1, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model|k-Fold|Sk-Fold\n",
    "-|-|-\n",
    "DecisionTree Classifier|0.666|0.7010763737633329\n",
    "RandomForest Classifier|0.702|0.7337106491739855\n",
    "XGBoost Classifier|0.794|0.7697288586617749\n",
    "Light GBM Classifier|0.794|0.7796600062893523 --> 최고 성능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
