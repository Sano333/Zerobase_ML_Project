{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 두 번째 모델링 : 근로기간 Unknown 값을 knn imputer로 대체한 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train = pd.read_csv('train_new_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>대출금액</th>\n",
       "      <th>대출기간</th>\n",
       "      <th>근로기간</th>\n",
       "      <th>주택소유상태</th>\n",
       "      <th>연간소득</th>\n",
       "      <th>부채_대비_소득_비율</th>\n",
       "      <th>총계좌수</th>\n",
       "      <th>대출목적</th>\n",
       "      <th>최근_2년간_연체_횟수</th>\n",
       "      <th>총상환원금</th>\n",
       "      <th>총상환이자</th>\n",
       "      <th>총연체금액</th>\n",
       "      <th>연체계좌수</th>\n",
       "      <th>대출등급</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12480000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72000000.0</td>\n",
       "      <td>18.90</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14400000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130800000.0</td>\n",
       "      <td>22.33</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373572.0</td>\n",
       "      <td>234060.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12000000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96000000.0</td>\n",
       "      <td>8.60</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>928644.0</td>\n",
       "      <td>151944.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14400000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132000000.0</td>\n",
       "      <td>15.09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>325824.0</td>\n",
       "      <td>153108.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18000000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71736000.0</td>\n",
       "      <td>25.39</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228540.0</td>\n",
       "      <td>148956.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         대출금액  대출기간  근로기간  주택소유상태         연간소득  부채_대비_소득_비율  총계좌수  대출목적  \\\n",
       "0  12480000.0   3.0   6.0     2.0   72000000.0        18.90  15.0   1.0   \n",
       "1  14400000.0   5.0  10.0     0.0  130800000.0        22.33  21.0  10.0   \n",
       "2  12000000.0   3.0   5.0     0.0   96000000.0         8.60  14.0   1.0   \n",
       "3  14400000.0   3.0   8.0     0.0  132000000.0        15.09  15.0   1.0   \n",
       "4  18000000.0   5.0   7.0     2.0   71736000.0        25.39  19.0   8.0   \n",
       "\n",
       "   최근_2년간_연체_횟수     총상환원금     총상환이자  총연체금액  연체계좌수  대출등급  \n",
       "0           0.0       0.0       0.0    0.0    0.0   2.0  \n",
       "1           0.0  373572.0  234060.0    0.0    0.0   1.0  \n",
       "2           0.0  928644.0  151944.0    0.0    0.0   0.0  \n",
       "3           0.0  325824.0  153108.0    0.0    0.0   2.0  \n",
       "4           0.0  228540.0  148956.0    0.0    0.0   1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:, :-1]\n",
    "y = train.iloc[:, -1]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_ss = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_ss, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model, params, random=False):\n",
    "    clf = model\n",
    "    if not random:\n",
    "        grid = GridSearchCV(clf, params,\n",
    "                                scoring='f1_macro', cv=5,\n",
    "                                n_jobs=-1)\n",
    "    else:\n",
    "        grid = RandomizedSearchCV(clf, params, n_iter=10,\n",
    "                                scoring='f1_macro', cv=5,\n",
    "                                n_jobs=-1, random_state=42)\n",
    "        \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    best_params = grid.best_params_\n",
    "    print(\"최상의 매개변수:\", best_params)\n",
    "    \n",
    "    best_score = grid.best_score_\n",
    "    print(\"훈련 점수: {:.3f}\".format(best_score))\n",
    "    \n",
    "    y_pred = best_model.predict(X_val)\n",
    "    macro_f1_val = f1_score(y_val, y_pred, average='macro')\n",
    "    print('테스트 세트 점수: {:.3f}'.format(macro_f1_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'min_samples_leaf': 19, 'min_impurity_decrease': 0.0, 'max_features': 0.68, 'max_depth': 17, 'class_weight': None}\n",
      "훈련 점수: 0.668\n",
      "테스트 세트 점수: 0.686\n"
     ]
    }
   ],
   "source": [
    "params = {'min_samples_leaf':[18,19,20,21,22],\n",
    "          'min_impurity_decrease':[0.0],\n",
    "          'max_features':['auto',0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.69,0.70],\n",
    "          'max_depth':[None,11,12,13,14,15,16,17,18],\n",
    "          'class_weight' : [None, 'balanced']}\n",
    "\n",
    "grid_search(DecisionTreeClassifier(random_state=42), params, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'n_estimators': 770, 'min_samples_leaf': 20, 'min_impurity_decrease': 0, 'max_features': 0.65, 'max_depth': 90}\n",
      "훈련 점수: 0.688\n",
      "테스트 세트 점수: 0.708\n"
     ]
    }
   ],
   "source": [
    "params = {'min_samples_leaf':[20],\n",
    "          'min_impurity_decrease':[0],\n",
    "          'max_features':[0.65,0.6,0.55],\n",
    "          'max_depth':[85,90,95],\n",
    "          'n_estimators' : [730,750,770]}\n",
    "\n",
    "grid_search(RandomForestClassifier(n_jobs=-1, random_state=42), params, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최상의 매개변수: {'n_estimators': 700, 'min_samples_leaf': 20, 'min_impurity_decrease': 0.0, 'max_features': 0.5, 'max_depth': 80}\n",
    "훈련 점수: 0.651\n",
    "테스트 세트 점수: 0.661"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "36분 소요\n",
    "\n",
    "최상의 매개변수: {'n_estimators': 750, 'min_samples_leaf': 20, 'min_impurity_decrease': 0, 'max_features': 0.6, 'max_depth': 90}\n",
    "훈련 점수: 0.668\n",
    "테스트 세트 점수: 0.683"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "45분.. 시간상 후행 작업 중단\n",
    "\n",
    "최상의 매개변수: {'n_estimators': 770, 'min_samples_leaf': 20, 'min_impurity_decrease': 0, 'max_features': 0.65, 'max_depth': 90}\n",
    "훈련 점수: 0.688\n",
    "테스트 세트 점수: 0.708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'objective': 'multi:softmax', 'n_estimators': 130, 'max_depth': 34, 'learning_rate': 0.18}\n",
      "훈련 점수: 0.794\n",
      "테스트 세트 점수: 0.794\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators' : [130,150,170],\n",
    "          'learning_rate' : [0.18,0.2,0.22],\n",
    "          'max_depth' : [33,34,35,36,37],\n",
    "          'objective' : ['multi:softmax']}\n",
    "\n",
    "grid_search(XGBClassifier(random_state=42, n_jobs=-1), params, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최상의 매개변수: {'objective': 'multi:softprob', 'n_estimators': 200, 'max_depth': 40, 'learning_rate': 0.2}\n",
    "훈련 점수: 0.794\n",
    "테스트 세트 점수: 0.792"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10분 소요\n",
    "\n",
    "최상의 매개변수: {'objective': 'multi:softmax', 'n_estimators': 150, 'max_depth': 35, 'learning_rate': 0.2}\n",
    "훈련 점수: 0.795\n",
    "테스트 세트 점수: 0.794"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9분 -> 성능 변화 거의 없음. 이거 사용\n",
    "\n",
    "최상의 매개변수: {'objective': 'multi:softmax', 'n_estimators': 130, 'max_depth': 34, 'learning_rate': 0.18}\n",
    "훈련 점수: 0.794\n",
    "테스트 세트 점수: 0.794"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1456\n",
      "[LightGBM] [Info] Number of data points in the train set: 67405, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747717\n",
      "[LightGBM] [Info] Start training from score -1.206424\n",
      "[LightGBM] [Info] Start training from score -1.248802\n",
      "[LightGBM] [Info] Start training from score -1.975557\n",
      "[LightGBM] [Info] Start training from score -2.572111\n",
      "[LightGBM] [Info] Start training from score -3.897369\n",
      "[LightGBM] [Info] Start training from score -5.434895\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "최상의 매개변수: {'num_leaves': 45, 'n_estimators': 360, 'max_depth': 12, 'learning_rate': 0.08}\n",
      "훈련 점수: 0.785\n",
      "테스트 세트 점수: 0.785\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators' : [340,350,360],\n",
    "          'learning_rate' : [0.05,0.06,0.07,0.08,0.09],\n",
    "          'max_depth' : [8,9,10,11,12],\n",
    "          'num_leaves' : [43,45,47]}\n",
    "\n",
    "grid_search(LGBMClassifier(objective='multiclass', random_state=42, n_jobs=-1), params, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최상의 매개변수: {'num_leaves': 40, 'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.05}\n",
    "훈련 점수: 0.779\n",
    "테스트 세트 점수: 0.786"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6분 소요\n",
    "\n",
    "최상의 매개변수: {'num_leaves': 45, 'n_estimators': 350, 'max_depth': 10, 'learning_rate': 0.07}\n",
    "훈련 점수: 0.785\n",
    "테스트 세트 점수: 0.785"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6분 -> 성능변화 거의 없음. 이거 사용\n",
    "\n",
    "최상의 매개변수: {'num_leaves': 45, 'n_estimators': 360, 'max_depth': 12, 'learning_rate': 0.08}\n",
    "훈련 점수: 0.785\n",
    "테스트 세트 점수: 0.785"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X_ss = pd.DataFrame(X_ss, columns=X.columns)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "f1_macro_scores = []\n",
    "\n",
    "def skf_score(model):\n",
    "    for train_idx, valid_idx in skf.split(X_ss, y):\n",
    "        X_train = X_ss.iloc[train_idx]\n",
    "        X_val = y.iloc[train_idx]\n",
    "\n",
    "        y_train = X_ss.iloc[valid_idx]\n",
    "        y_val = y.iloc[valid_idx]\n",
    "\n",
    "        model.fit(X_train, X_val)\n",
    "\n",
    "        pred = model.predict(y_train)\n",
    "\n",
    "        f1_macro = f1_score(y_val, pred, average='macro')\n",
    "        f1_macro_scores.append(f1_macro)\n",
    "    \n",
    "    average_f1_macro = np.mean(f1_macro_scores)\n",
    "\n",
    "    print(\"Average F1-macro score:\", average_f1_macro)\n",
    "    try:\n",
    "        if model.feature_importances_.any():\n",
    "            feature_importances = model.feature_importances_\n",
    "            print(\"\\n\",'-'*10,'특성중요도','-'*10)\n",
    "            for feature, importance in zip(X_ss.columns, feature_importances):\n",
    "                print(f\"{feature}: {importance}\")\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-macro score: 0.6966618175326169\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "대출금액: 0.057607057926605525\n",
      "대출기간: 0.0325371434609713\n",
      "근로기간: 0.0016173114754242752\n",
      "주택소유상태: 0.0010188254708840736\n",
      "연간소득: 0.006211342461809011\n",
      "부채_대비_소득_비율: 0.01409643635137708\n",
      "총계좌수: 0.0027563047729122062\n",
      "대출목적: 0.002383459725660737\n",
      "최근_2년간_연체_횟수: 0.0004418932682137579\n",
      "총상환원금: 0.5502363624581739\n",
      "총상환이자: 0.33109386262796814\n",
      "총연체금액: 0.0\n",
      "연체계좌수: 0.0\n"
     ]
    }
   ],
   "source": [
    "skf_score(DecisionTreeClassifier(min_samples_leaf=19, min_impurity_decrease=0, max_features=0.68,\n",
    "                                 max_depth=17, class_weight=None, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-macro score: 0.7167816163115104\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "대출금액: 0.050826232153413406\n",
      "대출기간: 0.04547071830990656\n",
      "근로기간: 0.0028354894652486483\n",
      "주택소유상태: 0.0016484482560358566\n",
      "연간소득: 0.017670662409359016\n",
      "부채_대비_소득_비율: 0.011231214685143194\n",
      "총계좌수: 0.005353223319572358\n",
      "대출목적: 0.004178031471702471\n",
      "최근_2년간_연체_횟수: 0.001274893230546957\n",
      "총상환원금: 0.4528059074110537\n",
      "총상환이자: 0.4067051792880177\n",
      "총연체금액: 0.0\n",
      "연체계좌수: 0.0\n"
     ]
    }
   ],
   "source": [
    "skf_score(RandomForestClassifier(n_estimators=770, min_samples_leaf=20, min_impurity_decrease=0, \n",
    "                                 max_features=0.65, max_depth=90, random_state=42, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-macro score: 0.7466399349797003\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "대출금액: 0.029054811224341393\n",
      "대출기간: 0.5254350900650024\n",
      "근로기간: 0.01224927231669426\n",
      "주택소유상태: 0.012388147413730621\n",
      "연간소득: 0.018565339967608452\n",
      "부채_대비_소득_비율: 0.01300264522433281\n",
      "총계좌수: 0.013052946887910366\n",
      "대출목적: 0.017211686819791794\n",
      "최근_2년간_연체_횟수: 0.01752505637705326\n",
      "총상환원금: 0.14957977831363678\n",
      "총상환이자: 0.16137993335723877\n",
      "총연체금액: 0.01628206856548786\n",
      "연체계좌수: 0.014273281209170818\n"
     ]
    }
   ],
   "source": [
    "skf_score(XGBClassifier(objective='multi:softmax', n_estimators=200, max_depth=40, \n",
    "          learning_rate=0.2, n_jobs=-1, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002823 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1462\n",
      "[LightGBM] [Info] Number of data points in the train set: 86663, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747730\n",
      "[LightGBM] [Info] Start training from score -1.206395\n",
      "[LightGBM] [Info] Start training from score -1.248807\n",
      "[LightGBM] [Info] Start training from score -1.975538\n",
      "[LightGBM] [Info] Start training from score -2.572234\n",
      "[LightGBM] [Info] Start training from score -3.897282\n",
      "[LightGBM] [Info] Start training from score -5.434888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1469\n",
      "[LightGBM] [Info] Number of data points in the train set: 86663, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747663\n",
      "[LightGBM] [Info] Start training from score -1.206395\n",
      "[LightGBM] [Info] Start training from score -1.248807\n",
      "[LightGBM] [Info] Start training from score -1.975622\n",
      "[LightGBM] [Info] Start training from score -2.572234\n",
      "[LightGBM] [Info] Start training from score -3.897282\n",
      "[LightGBM] [Info] Start training from score -5.434888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 86663, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747663\n",
      "[LightGBM] [Info] Start training from score -1.206434\n",
      "[LightGBM] [Info] Start training from score -1.248767\n",
      "[LightGBM] [Info] Start training from score -1.975622\n",
      "[LightGBM] [Info] Start training from score -2.572234\n",
      "[LightGBM] [Info] Start training from score -3.897282\n",
      "[LightGBM] [Info] Start training from score -5.434888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1467\n",
      "[LightGBM] [Info] Number of data points in the train set: 86664, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747675\n",
      "[LightGBM] [Info] Start training from score -1.206445\n",
      "[LightGBM] [Info] Start training from score -1.248778\n",
      "[LightGBM] [Info] Start training from score -1.975633\n",
      "[LightGBM] [Info] Start training from score -2.572094\n",
      "[LightGBM] [Info] Start training from score -3.897293\n",
      "[LightGBM] [Info] Start training from score -5.434900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1467\n",
      "[LightGBM] [Info] Number of data points in the train set: 86664, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747675\n",
      "[LightGBM] [Info] Start training from score -1.206445\n",
      "[LightGBM] [Info] Start training from score -1.248778\n",
      "[LightGBM] [Info] Start training from score -1.975633\n",
      "[LightGBM] [Info] Start training from score -2.572094\n",
      "[LightGBM] [Info] Start training from score -3.897293\n",
      "[LightGBM] [Info] Start training from score -5.434900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 86664, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747675\n",
      "[LightGBM] [Info] Start training from score -1.206445\n",
      "[LightGBM] [Info] Start training from score -1.248778\n",
      "[LightGBM] [Info] Start training from score -1.975550\n",
      "[LightGBM] [Info] Start training from score -2.572094\n",
      "[LightGBM] [Info] Start training from score -3.897862\n",
      "[LightGBM] [Info] Start training from score -5.434900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1464\n",
      "[LightGBM] [Info] Number of data points in the train set: 86664, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747675\n",
      "[LightGBM] [Info] Start training from score -1.206445\n",
      "[LightGBM] [Info] Start training from score -1.248778\n",
      "[LightGBM] [Info] Start training from score -1.975550\n",
      "[LightGBM] [Info] Start training from score -2.572094\n",
      "[LightGBM] [Info] Start training from score -3.897862\n",
      "[LightGBM] [Info] Start training from score -5.434900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1468\n",
      "[LightGBM] [Info] Number of data points in the train set: 86664, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747675\n",
      "[LightGBM] [Info] Start training from score -1.206445\n",
      "[LightGBM] [Info] Start training from score -1.248778\n",
      "[LightGBM] [Info] Start training from score -1.975550\n",
      "[LightGBM] [Info] Start training from score -2.572094\n",
      "[LightGBM] [Info] Start training from score -3.897862\n",
      "[LightGBM] [Info] Start training from score -5.434900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1466\n",
      "[LightGBM] [Info] Number of data points in the train set: 86664, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747675\n",
      "[LightGBM] [Info] Start training from score -1.206445\n",
      "[LightGBM] [Info] Start training from score -1.248778\n",
      "[LightGBM] [Info] Start training from score -1.975550\n",
      "[LightGBM] [Info] Start training from score -2.572094\n",
      "[LightGBM] [Info] Start training from score -3.897862\n",
      "[LightGBM] [Info] Start training from score -5.434900\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1467\n",
      "[LightGBM] [Info] Number of data points in the train set: 86664, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.747741\n",
      "[LightGBM] [Info] Start training from score -1.206407\n",
      "[LightGBM] [Info] Start training from score -1.248778\n",
      "[LightGBM] [Info] Start training from score -1.975550\n",
      "[LightGBM] [Info] Start training from score -2.572245\n",
      "[LightGBM] [Info] Start training from score -3.897293\n",
      "[LightGBM] [Info] Start training from score -5.434900\n",
      "Average F1-macro score: 0.7761664858844045\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "대출금액: 11464\n",
      "대출기간: 2662\n",
      "근로기간: 2300\n",
      "주택소유상태: 933\n",
      "연간소득: 6010\n",
      "부채_대비_소득_비율: 6403\n",
      "총계좌수: 4862\n",
      "대출목적: 2183\n",
      "최근_2년간_연체_횟수: 1039\n",
      "총상환원금: 23533\n",
      "총상환이자: 19927\n",
      "총연체금액: 507\n",
      "연체계좌수: 77\n"
     ]
    }
   ],
   "source": [
    "skf_score(LGBMClassifier(objective='multiclass', num_leaves=45, n_estimators=360, max_depth=12, \n",
    "               learning_rate=0.08, n_jobs=-1, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model|k-Fold|Sk-Fold\n",
    "-|-|-\n",
    "DecisionTree Classifier|0.686|0.6966618175326169\n",
    "RandomForest Classifier|0.708|0.7167816163115104\n",
    "XGBoost Classifier|0.794|0.770969787812605\n",
    "Light GBM Classifier|0.785|0.7761664858844045 --> 최고 성능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
