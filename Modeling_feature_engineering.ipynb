{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 진행중인 대출등급 예측의 목표를 다시 생각해보자.\n",
    "\n",
    "객관적 자료를 배제하고, '내가' 생각했을 때 등급 산정 시 가장 중요한 특성 5가지만 생각해보면\n",
    "\n",
    "연간소득, 총상환원금과 이자 그리고 연체와 관련된 부분이다.\n",
    "\n",
    "따라서 연간소득, 총상환원금, 총상환이자, 최근2년간연체횟수, 총연체금액, 연체계좌수 6개 컬럼만 이용하여 모델링을 시도해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연간소득</th>\n",
       "      <th>최근_2년간_연체_횟수</th>\n",
       "      <th>총상환원금</th>\n",
       "      <th>총상환이자</th>\n",
       "      <th>총연체금액</th>\n",
       "      <th>연체계좌수</th>\n",
       "      <th>대출등급</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130800000</td>\n",
       "      <td>0</td>\n",
       "      <td>373572</td>\n",
       "      <td>234060.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96000000</td>\n",
       "      <td>0</td>\n",
       "      <td>928644</td>\n",
       "      <td>151944.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132000000</td>\n",
       "      <td>0</td>\n",
       "      <td>325824</td>\n",
       "      <td>153108.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84000000</td>\n",
       "      <td>0</td>\n",
       "      <td>240216</td>\n",
       "      <td>55428.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        연간소득  최근_2년간_연체_횟수   총상환원금     총상환이자  총연체금액  연체계좌수 대출등급\n",
       "0   72000000             0       0       0.0    0.0    0.0    C\n",
       "1  130800000             0  373572  234060.0    0.0    0.0    B\n",
       "2   96000000             0  928644  151944.0    0.0    0.0    A\n",
       "3  132000000             0  325824  153108.0    0.0    0.0    C\n",
       "4   84000000             0  240216   55428.0    0.0    0.0    A"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./train_new.csv')\n",
    "train.drop(['ID', '대출기간', '대출금액', '근로기간', '주택소유상태', '부채_대비_소득_비율', '총계좌수', '대출목적'], axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "train['대출등급'] = le.fit_transform(train['대출등급'])\n",
    "\n",
    "X = train.iloc[:, :-1]\n",
    "y = train.iloc[:, -1]\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_ss = ss.fit_transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_ss, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model, params, random=False):\n",
    "    clf = model\n",
    "    if not random:\n",
    "        grid = GridSearchCV(clf, params,\n",
    "                                scoring='f1_macro', cv=5,\n",
    "                                n_jobs=-1)\n",
    "    else:\n",
    "        grid = RandomizedSearchCV(clf, params, n_iter=10,\n",
    "                                scoring='f1_macro', cv=5,\n",
    "                                n_jobs=-1, random_state=42)\n",
    "        \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    \n",
    "    best_params = grid.best_params_\n",
    "    print(\"최상의 매개변수:\", best_params)\n",
    "    \n",
    "    best_score = grid.best_score_\n",
    "    print(\"훈련 점수: {:.3f}\".format(best_score))\n",
    "    \n",
    "    y_pred = best_model.predict(X_val)\n",
    "    macro_f1_val = f1_score(y_val, y_pred, average='macro')\n",
    "    print('테스트 세트 점수: {:.3f}'.format(macro_f1_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'min_samples_leaf': 19, 'min_impurity_decrease': 0.0, 'max_features': 0.68, 'max_depth': 17, 'class_weight': None}\n",
      "훈련 점수: 0.668\n",
      "테스트 세트 점수: 0.706\n"
     ]
    }
   ],
   "source": [
    "params = {'min_samples_leaf':[18,19,20,21,22],\n",
    "          'min_impurity_decrease':[0.0],\n",
    "          'max_features':['auto',0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.69,0.70],\n",
    "          'max_depth':[None,11,12,13,14,15,16,17,18],\n",
    "          'class_weight' : [None, 'balanced']}\n",
    "\n",
    "grid_search(DecisionTreeClassifier(random_state=42), params, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최상의 매개변수: {'min_samples_leaf': 19, 'min_impurity_decrease': 0.0, 'max_features': 0.68, 'max_depth': 17, 'class_weight': None}\n",
    "훈련 점수: 0.668\n",
    "테스트 세트 점수: 0.706"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'n_estimators': 770, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_features': 0.73, 'max_depth': 95}\n",
      "훈련 점수: 0.774\n",
      "테스트 세트 점수: 0.776\n"
     ]
    }
   ],
   "source": [
    "params = {'min_samples_leaf':[1,3,5],\n",
    "          'min_impurity_decrease':[0.0],\n",
    "          'max_features':[0.71,0.73,0.75],\n",
    "          'max_depth':[91,93,95,97,99],\n",
    "          'n_estimators' : [750,770,790,810,830,850]}\n",
    "\n",
    "grid_search(RandomForestClassifier(n_jobs=-1, random_state=42), params, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최상의 매개변수: {'n_estimators': 700, 'min_samples_leaf': 20, 'min_impurity_decrease': 0.0, 'max_features': 0.5, 'max_depth': 80}\n",
    "훈련 점수: 0.638\n",
    "테스트 세트 점수: 0.650"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "48분 소요로 후행 작업 중단\n",
    "\n",
    "최상의 매개변수: {'n_estimators': 770, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_features': 0.73, 'max_depth': 95}\n",
    "훈련 점수: 0.774\n",
    "테스트 세트 점수: 0.776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'objective': 'multi:softmax', 'n_estimators': 250, 'max_depth': 110, 'learning_rate': 0.01}\n",
      "훈련 점수: 0.748\n",
      "테스트 세트 점수: 0.750\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators' : [150,200,250],\n",
    "          'learning_rate' : [0.01,0.05,0.1],\n",
    "          'max_depth' : [90,100,110],\n",
    "          'objective' : ['multi:softmax']}\n",
    "\n",
    "grid_search(XGBClassifier(random_state=42, n_jobs=-1), params, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최상의 매개변수: {'objective': 'multi:softmax', 'n_estimators': 200, 'max_depth': 100, 'learning_rate': 0.01}\n",
    "훈련 점수: 0.750\n",
    "테스트 세트 점수: 0.749"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20분 - 성능변화 크게 없음\n",
    "\n",
    "최상의 매개변수: {'objective': 'multi:softmax', 'n_estimators': 250, 'max_depth': 110, 'learning_rate': 0.01}\n",
    "훈련 점수: 0.748\n",
    "테스트 세트 점수: 0.750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 818\n",
      "[LightGBM] [Info] Number of data points in the train set: 63435, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744243\n",
      "[LightGBM] [Info] Start training from score -1.208106\n",
      "[LightGBM] [Info] Start training from score -1.248814\n",
      "[LightGBM] [Info] Start training from score -1.982449\n",
      "[LightGBM] [Info] Start training from score -2.564256\n",
      "[LightGBM] [Info] Start training from score -3.885346\n",
      "[LightGBM] [Info] Start training from score -5.433754\n",
      "최상의 매개변수: {'num_leaves': 30, 'n_estimators': 500, 'max_depth': 125, 'learning_rate': 0.05}\n",
      "훈련 점수: 0.743\n",
      "테스트 세트 점수: 0.737\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators' : [450,500,550,600],\n",
    "          'learning_rate' : [0.01,0.05,0.1,0.2,0.3,0.4],\n",
    "          'max_depth' : [75,100,125,150],\n",
    "          'num_leaves' : [20,25,30]}\n",
    "\n",
    "grid_search(LGBMClassifier(objective='multiclass', random_state=42, n_jobs=-1), params, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최상의 매개변수: {'num_leaves': 25, 'n_estimators': 500, 'max_depth': 100, 'learning_rate': 0.1}\n",
    "훈련 점수: 0.738\n",
    "테스트 세트 점수: 0.736"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8분 - 성능 변화 크게 없음\n",
    "\n",
    "최상의 매개변수: {'num_leaves': 30, 'n_estimators': 500, 'max_depth': 125, 'learning_rate': 0.05}\n",
    "훈련 점수: 0.743\n",
    "테스트 세트 점수: 0.737"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ss = pd.DataFrame(X_ss, columns=X.columns)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "f1_macro_scores = []\n",
    "\n",
    "def skf_score(model):\n",
    "    for train_idx, valid_idx in skf.split(X_ss, y):\n",
    "        X_train = X_ss.iloc[train_idx]\n",
    "        X_val = y.iloc[train_idx]\n",
    "\n",
    "        y_train = X_ss.iloc[valid_idx]\n",
    "        y_val = y.iloc[valid_idx]\n",
    "\n",
    "        model.fit(X_train, X_val)\n",
    "\n",
    "        pred = model.predict(y_train)\n",
    "\n",
    "        f1_macro = f1_score(y_val, pred, average='macro')\n",
    "        f1_macro_scores.append(f1_macro)\n",
    "    \n",
    "    average_f1_macro = np.mean(f1_macro_scores)\n",
    "\n",
    "    print(\"Average F1-macro score:\", average_f1_macro)\n",
    "    try:\n",
    "        if model.feature_importances_.any():\n",
    "            feature_importances = model.feature_importances_\n",
    "            print(\"\\n\",'-'*10,'특성중요도','-'*10)\n",
    "            for feature, importance in zip(X_ss.columns, feature_importances):\n",
    "                print(f\"{feature}: {importance}\")\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-macro score: 0.7056080563919831\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "연간소득: 0.031204710863173352\n",
      "최근_2년간_연체_횟수: 0.0018175221538471197\n",
      "총상환원금: 0.5644763422936642\n",
      "총상환이자: 0.4025014246893154\n",
      "총연체금액: 0.0\n",
      "연체계좌수: 0.0\n"
     ]
    }
   ],
   "source": [
    "skf_score(DecisionTreeClassifier(min_samples_leaf=19, min_impurity_decrease=0, \n",
    "                                 max_features=0.68, max_depth=17, class_weight=None, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-macro score: 0.747356297190938\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "연간소득: 0.09318574941085862\n",
      "최근_2년간_연체_횟수: 0.014293254197159409\n",
      "총상환원금: 0.4798765292562635\n",
      "총상환이자: 0.4110978759495366\n",
      "총연체금액: 0.0007683069149552781\n",
      "연체계좌수: 0.0007782842712264112\n"
     ]
    }
   ],
   "source": [
    "skf_score(RandomForestClassifier(n_estimators=770, min_samples_leaf=1, min_impurity_decrease=0, \n",
    "                                 max_features=0.73, max_depth=95, random_state=42, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-macro score: 0.7524633595010309\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "연간소득: 0.05038720369338989\n",
      "최근_2년간_연체_횟수: 0.04464619606733322\n",
      "총상환원금: 0.39258119463920593\n",
      "총상환이자: 0.402171790599823\n",
      "총연체금액: 0.06731744110584259\n",
      "연체계좌수: 0.04289612919092178\n"
     ]
    }
   ],
   "source": [
    "skf_score(XGBClassifier(objective='multi:softmax', n_estimators=250, max_depth=110, \n",
    "          learning_rate=0.01, n_jobs=-1, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 81559, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744289\n",
      "[LightGBM] [Info] Start training from score -1.208056\n",
      "[LightGBM] [Info] Start training from score -1.248847\n",
      "[LightGBM] [Info] Start training from score -1.982382\n",
      "[LightGBM] [Info] Start training from score -2.564275\n",
      "[LightGBM] [Info] Start training from score -3.885514\n",
      "[LightGBM] [Info] Start training from score -5.434151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 825\n",
      "[LightGBM] [Info] Number of data points in the train set: 81559, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744289\n",
      "[LightGBM] [Info] Start training from score -1.208056\n",
      "[LightGBM] [Info] Start training from score -1.248847\n",
      "[LightGBM] [Info] Start training from score -1.982382\n",
      "[LightGBM] [Info] Start training from score -2.564275\n",
      "[LightGBM] [Info] Start training from score -3.884917\n",
      "[LightGBM] [Info] Start training from score -5.436964\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208068\n",
      "[LightGBM] [Info] Start training from score -1.248859\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 823\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208068\n",
      "[LightGBM] [Info] Start training from score -1.248859\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 826\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 824\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744231\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982483\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744231\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982483\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 825\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208068\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.885526\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "Average F1-macro score: 0.752895857025268\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "연간소득: 19552\n",
      "최근_2년간_연체_횟수: 3540\n",
      "총상환원금: 39849\n",
      "총상환이자: 37182\n",
      "총연체금액: 1116\n",
      "연체계좌수: 261\n"
     ]
    }
   ],
   "source": [
    "skf_score(LGBMClassifier(objective='multiclass', num_leaves=30, n_estimators=500, max_depth=125, \n",
    "               learning_rate=0.05, n_jobs=-1, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 81559, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744289\n",
      "[LightGBM] [Info] Start training from score -1.208056\n",
      "[LightGBM] [Info] Start training from score -1.248847\n",
      "[LightGBM] [Info] Start training from score -1.982382\n",
      "[LightGBM] [Info] Start training from score -2.564275\n",
      "[LightGBM] [Info] Start training from score -3.885514\n",
      "[LightGBM] [Info] Start training from score -5.434151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 825\n",
      "[LightGBM] [Info] Number of data points in the train set: 81559, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744289\n",
      "[LightGBM] [Info] Start training from score -1.208056\n",
      "[LightGBM] [Info] Start training from score -1.248847\n",
      "[LightGBM] [Info] Start training from score -1.982382\n",
      "[LightGBM] [Info] Start training from score -2.564275\n",
      "[LightGBM] [Info] Start training from score -3.884917\n",
      "[LightGBM] [Info] Start training from score -5.436964\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208068\n",
      "[LightGBM] [Info] Start training from score -1.248859\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 823\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208068\n",
      "[LightGBM] [Info] Start training from score -1.248859\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 826\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 824\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744231\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982483\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744231\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982483\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 825\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208068\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.885526\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "Average F1-macro score: 0.7542865437715123\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "연간소득: 97451\n",
      "최근_2년간_연체_횟수: 15473\n",
      "총상환원금: 153713\n",
      "총상환이자: 148991\n",
      "총연체금액: 3455\n",
      "연체계좌수: 917\n"
     ]
    }
   ],
   "source": [
    "skf_score(LGBMClassifier(objective='multiclass', num_leaves=41, n_estimators=1500, max_depth=130, \n",
    "               learning_rate=0.024, n_jobs=-1, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB를 제외하고 총상환원금과 총상환이자의 특성 중요도가 90% 이상을 차지했다.\n",
    "\n",
    "총상환원금과 총상환이자 컬럼이 중요한건 알겠는데.. 이걸 어떻게 활용하면 좋을까?\n",
    "\n",
    "model|k-Fold|Sk-Fold\n",
    "-|-|-\n",
    "DecisionTree Classifier|0.706|0.7056080563919831\n",
    "RandomForest Classifier|0.776|0.747356297190938\n",
    "XGBoost Classifier|0.750|0.7524633595010309\n",
    "Light GBM Classifier|0.737|0.752895857025268 --> 최고 성능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파생변수 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 앞서 특성 중요도를 살펴보았을 때 총상환원금과 총상환이자 2개의 컬럼의 중요도가 매우 높게 나타났다. \n",
    "\n",
    "### 이 두가지 컬럼을 이용하여 파생변수를 생성해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 상호 작용 변수 생성\n",
    "\n",
    "상호 작용 변수를 만드는 것은 모델에 미치는 다양한 변수 간의 상호 작용을 고려하여 모델의 품질을 향상시킬 수 있는 중요한 전략이다.\n",
    "\n",
    "상호 작용 변수는 두 변수 간의 곱셈이나 나눗셈 등을 통해 생성될 수 있는데, 예를 들면 변수 A와 변수 B의 상호 작용은 A * B와 같이 표현된다.\n",
    "\n",
    "그러나 상호 작용 변수를 생성하는 데 있어서 주의할 점은 모든 가능한 조합을 만들 필요는 없다는 것. \n",
    "\n",
    "특히, 도메인 지식이나 특정 가정에 기반하여 어떤 변수 간의 상호 작용이 중요한지를 결정하는 것이 좋다. \n",
    "\n",
    "무작정 모든 변수의 조합을 만들면 모델이 복잡해지고 과적합의 위험이 있기 때문\n",
    "\n",
    "예를 들어, LinearRegression 모델에서는 주요 예측 변수들 간의 상호 작용을 추가하여 모델의 설명력을 높일 수 있다. 하지만 모델의 유연성을 고려하여 필요한 상호 작용만을 추가하는 것이 매우 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 총상환원금 + 총상환이자\n",
    "2. 총상환원금 - 총상환이자\n",
    "3. 총상환원금 * 총상환이자\n",
    "4. 총상환원금^2\n",
    "5. 총상환이자^2\n",
    "6. sqrt(총상환원금)\n",
    "7. sqrt(총상환이자)\n",
    "\n",
    "총 7가지 파생변수를 생성해서 모델링 해본 뒤 과적합의 위험이 보이면 차원을 축소하는 걸로 진행해보자\n",
    "\n",
    "(log 값도 추가하려 했으나 무한대 값을 처리하는 방법을 찾지 못해 일단 7개만 진행)\n",
    "\n",
    "++ 연체에 대한 컬럼도 영향력이 작으니 과감하게 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연간소득</th>\n",
       "      <th>총상환원금</th>\n",
       "      <th>총상환이자</th>\n",
       "      <th>대출등급</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130800000</td>\n",
       "      <td>373572</td>\n",
       "      <td>234060.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96000000</td>\n",
       "      <td>928644</td>\n",
       "      <td>151944.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132000000</td>\n",
       "      <td>325824</td>\n",
       "      <td>153108.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84000000</td>\n",
       "      <td>240216</td>\n",
       "      <td>55428.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        연간소득   총상환원금     총상환이자 대출등급\n",
       "0   72000000       0       0.0    C\n",
       "1  130800000  373572  234060.0    B\n",
       "2   96000000  928644  151944.0    A\n",
       "3  132000000  325824  153108.0    C\n",
       "4   84000000  240216   55428.0    A"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./train_new.csv')\n",
    "train.drop(['ID', '대출기간', '대출금액', '근로기간', '주택소유상태', '최근_2년간_연체_횟수', '부채_대비_소득_비율', '총계좌수', '대출목적', '총연체금액', '연체계좌수'], axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['총상환원금+총상환이자'] = train['총상환원금'] + train['총상환이자']\n",
    "train['총상환원금-총상환이자'] = train['총상환원금'] - train['총상환이자']\n",
    "train['총상환원금*총상환이자'] = train['총상환원금'] * train['총상환이자']\n",
    "train['총상환원금^2'] = train['총상환원금']**2\n",
    "train['총상환이자^2'] = train['총상환이자']**2\n",
    "train['sqrt(총상환원금)'] = np.sqrt(train['총상환원금'])\n",
    "train['sqrt(총상환이자)'] = np.sqrt(train['총상환이자'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연간소득</th>\n",
       "      <th>총상환원금</th>\n",
       "      <th>총상환이자</th>\n",
       "      <th>대출등급</th>\n",
       "      <th>총상환원금+총상환이자</th>\n",
       "      <th>총상환원금-총상환이자</th>\n",
       "      <th>총상환원금*총상환이자</th>\n",
       "      <th>총상환원금^2</th>\n",
       "      <th>총상환이자^2</th>\n",
       "      <th>sqrt(총상환원금)</th>\n",
       "      <th>sqrt(총상환이자)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130800000</td>\n",
       "      <td>373572</td>\n",
       "      <td>234060.0</td>\n",
       "      <td>B</td>\n",
       "      <td>607632.0</td>\n",
       "      <td>139512.0</td>\n",
       "      <td>8.743826e+10</td>\n",
       "      <td>139556039184</td>\n",
       "      <td>5.478408e+10</td>\n",
       "      <td>611.205366</td>\n",
       "      <td>483.797478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96000000</td>\n",
       "      <td>928644</td>\n",
       "      <td>151944.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1080588.0</td>\n",
       "      <td>776700.0</td>\n",
       "      <td>1.411019e+11</td>\n",
       "      <td>862379678736</td>\n",
       "      <td>2.308698e+10</td>\n",
       "      <td>963.661766</td>\n",
       "      <td>389.799949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132000000</td>\n",
       "      <td>325824</td>\n",
       "      <td>153108.0</td>\n",
       "      <td>C</td>\n",
       "      <td>478932.0</td>\n",
       "      <td>172716.0</td>\n",
       "      <td>4.988626e+10</td>\n",
       "      <td>106161278976</td>\n",
       "      <td>2.344206e+10</td>\n",
       "      <td>570.809951</td>\n",
       "      <td>391.290174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84000000</td>\n",
       "      <td>240216</td>\n",
       "      <td>55428.0</td>\n",
       "      <td>A</td>\n",
       "      <td>295644.0</td>\n",
       "      <td>184788.0</td>\n",
       "      <td>1.331469e+10</td>\n",
       "      <td>57703726656</td>\n",
       "      <td>3.072263e+09</td>\n",
       "      <td>490.118353</td>\n",
       "      <td>235.431519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        연간소득   총상환원금     총상환이자 대출등급  총상환원금+총상환이자  총상환원금-총상환이자   총상환원금*총상환이자  \\\n",
       "0   72000000       0       0.0    C          0.0          0.0  0.000000e+00   \n",
       "1  130800000  373572  234060.0    B     607632.0     139512.0  8.743826e+10   \n",
       "2   96000000  928644  151944.0    A    1080588.0     776700.0  1.411019e+11   \n",
       "3  132000000  325824  153108.0    C     478932.0     172716.0  4.988626e+10   \n",
       "4   84000000  240216   55428.0    A     295644.0     184788.0  1.331469e+10   \n",
       "\n",
       "        총상환원금^2       총상환이자^2  sqrt(총상환원금)  sqrt(총상환이자)  \n",
       "0             0  0.000000e+00     0.000000     0.000000  \n",
       "1  139556039184  5.478408e+10   611.205366   483.797478  \n",
       "2  862379678736  2.308698e+10   963.661766   389.799949  \n",
       "3  106161278976  2.344206e+10   570.809951   391.290174  \n",
       "4   57703726656  3.072263e+09   490.118353   235.431519  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연간소득</th>\n",
       "      <th>총상환원금</th>\n",
       "      <th>총상환이자</th>\n",
       "      <th>총상환원금+총상환이자</th>\n",
       "      <th>총상환원금-총상환이자</th>\n",
       "      <th>총상환원금*총상환이자</th>\n",
       "      <th>총상환원금^2</th>\n",
       "      <th>총상환이자^2</th>\n",
       "      <th>sqrt(총상환원금)</th>\n",
       "      <th>sqrt(총상환이자)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>90622.000000</td>\n",
       "      <td>90622.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.602655e+07</td>\n",
       "      <td>8.326632e+05</td>\n",
       "      <td>4.350762e+05</td>\n",
       "      <td>1.267739e+06</td>\n",
       "      <td>3.975871e+05</td>\n",
       "      <td>5.508045e+11</td>\n",
       "      <td>1.779663e+12</td>\n",
       "      <td>3.865873e+11</td>\n",
       "      <td>813.354733</td>\n",
       "      <td>580.451919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.018091e+08</td>\n",
       "      <td>1.042279e+06</td>\n",
       "      <td>4.441826e+05</td>\n",
       "      <td>1.288687e+06</td>\n",
       "      <td>9.521424e+05</td>\n",
       "      <td>1.187096e+12</td>\n",
       "      <td>1.955229e+13</td>\n",
       "      <td>9.014668e+11</td>\n",
       "      <td>413.665583</td>\n",
       "      <td>313.293517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.432000e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.032960e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.880000e+07</td>\n",
       "      <td>3.126420e+05</td>\n",
       "      <td>1.378470e+05</td>\n",
       "      <td>4.952460e+05</td>\n",
       "      <td>3.764400e+04</td>\n",
       "      <td>4.777283e+10</td>\n",
       "      <td>9.774502e+10</td>\n",
       "      <td>1.900180e+10</td>\n",
       "      <td>559.143989</td>\n",
       "      <td>371.277524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.160000e+07</td>\n",
       "      <td>6.047280e+05</td>\n",
       "      <td>2.934180e+05</td>\n",
       "      <td>9.593280e+05</td>\n",
       "      <td>2.324520e+05</td>\n",
       "      <td>1.873828e+11</td>\n",
       "      <td>3.656960e+11</td>\n",
       "      <td>8.609412e+10</td>\n",
       "      <td>777.642591</td>\n",
       "      <td>541.680718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.140000e+08</td>\n",
       "      <td>1.067496e+06</td>\n",
       "      <td>5.794080e+05</td>\n",
       "      <td>1.705812e+06</td>\n",
       "      <td>5.644650e+05</td>\n",
       "      <td>5.912029e+11</td>\n",
       "      <td>1.139548e+12</td>\n",
       "      <td>3.357136e+11</td>\n",
       "      <td>1033.196980</td>\n",
       "      <td>761.188544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.080000e+10</td>\n",
       "      <td>4.195594e+07</td>\n",
       "      <td>5.653416e+06</td>\n",
       "      <td>4.233784e+07</td>\n",
       "      <td>4.157404e+07</td>\n",
       "      <td>7.705459e+13</td>\n",
       "      <td>1.760301e+15</td>\n",
       "      <td>3.196111e+13</td>\n",
       "      <td>6477.340195</td>\n",
       "      <td>2377.691317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               연간소득         총상환원금         총상환이자   총상환원금+총상환이자   총상환원금-총상환이자  \\\n",
       "count  9.062200e+04  9.062200e+04  9.062200e+04  9.062200e+04  9.062200e+04   \n",
       "mean   9.602655e+07  8.326632e+05  4.350762e+05  1.267739e+06  3.975871e+05   \n",
       "std    1.018091e+08  1.042279e+06  4.441826e+05  1.288687e+06  9.521424e+05   \n",
       "min    6.432000e+06  0.000000e+00  0.000000e+00  0.000000e+00 -4.032960e+06   \n",
       "25%    5.880000e+07  3.126420e+05  1.378470e+05  4.952460e+05  3.764400e+04   \n",
       "50%    8.160000e+07  6.047280e+05  2.934180e+05  9.593280e+05  2.324520e+05   \n",
       "75%    1.140000e+08  1.067496e+06  5.794080e+05  1.705812e+06  5.644650e+05   \n",
       "max    1.080000e+10  4.195594e+07  5.653416e+06  4.233784e+07  4.157404e+07   \n",
       "\n",
       "        총상환원금*총상환이자       총상환원금^2       총상환이자^2   sqrt(총상환원금)   sqrt(총상환이자)  \n",
       "count  9.062200e+04  9.062200e+04  9.062200e+04  90622.000000  90622.000000  \n",
       "mean   5.508045e+11  1.779663e+12  3.865873e+11    813.354733    580.451919  \n",
       "std    1.187096e+12  1.955229e+13  9.014668e+11    413.665583    313.293517  \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00      0.000000      0.000000  \n",
       "25%    4.777283e+10  9.774502e+10  1.900180e+10    559.143989    371.277524  \n",
       "50%    1.873828e+11  3.656960e+11  8.609412e+10    777.642591    541.680718  \n",
       "75%    5.912029e+11  1.139548e+12  3.357136e+11   1033.196980    761.188544  \n",
       "max    7.705459e+13  1.760301e+15  3.196111e+13   6477.340195   2377.691317  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.loc[:, train.columns != '대출등급']\n",
    "y = train.loc[:, ['대출등급']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "ss = StandardScaler()\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "X_ss = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_ss, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'min_samples_leaf': 19, 'min_impurity_decrease': 0.0, 'max_features': 0.68, 'max_depth': 17, 'class_weight': None}\n",
      "훈련 점수: 0.739\n",
      "테스트 세트 점수: 0.743\n"
     ]
    }
   ],
   "source": [
    "params = {'min_samples_leaf':[18,19,20,21,22],\n",
    "          'min_impurity_decrease':[0.0],\n",
    "          'max_features':['auto',0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.69,0.70],\n",
    "          'max_depth':[None,11,12,13,14,15,16,17,18],\n",
    "          'class_weight' : [None, 'balanced']}\n",
    "\n",
    "grid_search(DecisionTreeClassifier(random_state=42), params, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'n_estimators': 770, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_features': 0.73, 'max_depth': 95}\n",
      "훈련 점수: 0.794\n",
      "테스트 세트 점수: 0.787\n"
     ]
    }
   ],
   "source": [
    "params = {'min_samples_leaf':[1,3,5],\n",
    "          'min_impurity_decrease':[0.0],\n",
    "          'max_features':[0.71,0.73,0.75],\n",
    "          'max_depth':[91,93,95,97,99],\n",
    "          'n_estimators' : [750,770,790,810,830,850]}\n",
    "\n",
    "grid_search(RandomForestClassifier(n_jobs=-1, random_state=42), params, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.689"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "150분.. 소요되어 후행 작업 중단\n",
    "\n",
    "최상의 매개변수: {'n_estimators': 770, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_features': 0.73, 'max_depth': 95}\n",
    "훈련 점수: 0.794\n",
    "테스트 세트 점수: 0.787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'objective': 'multi:softmax', 'n_estimators': 250, 'max_depth': 90, 'learning_rate': 0.01}\n",
      "훈련 점수: 0.768\n",
      "테스트 세트 점수: 0.770\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators' : [150,175,200,225,250],\n",
    "          'learning_rate' : [0.01,0.025,0.05,0.075,0.1],\n",
    "          'max_depth' : [90,95,100,105,110],\n",
    "          'objective' : ['multi:softmax']}\n",
    "\n",
    "grid_search(XGBClassifier(random_state=42, n_jobs=-1), params, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최상의 매개변수: {'objective': 'multi:softmax', 'n_estimators': 200, 'max_depth': 100, 'learning_rate': 0.01}\n",
    "훈련 점수: 0.768\n",
    "테스트 세트 점수: 0.767"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33분 - 성능변화 크게 없음\n",
    "\n",
    "최상의 매개변수: {'objective': 'multi:softmax', 'n_estimators': 250, 'max_depth': 90, 'learning_rate': 0.01}\n",
    "훈련 점수: 0.768\n",
    "테스트 세트 점수: 0.770"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 63435, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744243\n",
      "[LightGBM] [Info] Start training from score -1.208106\n",
      "[LightGBM] [Info] Start training from score -1.248814\n",
      "[LightGBM] [Info] Start training from score -1.982449\n",
      "[LightGBM] [Info] Start training from score -2.564256\n",
      "[LightGBM] [Info] Start training from score -3.885346\n",
      "[LightGBM] [Info] Start training from score -5.433754\n",
      "최상의 매개변수: {'num_leaves': 37, 'n_estimators': 300, 'max_depth': 13, 'learning_rate': 0.05}\n",
      "훈련 점수: 0.771\n",
      "테스트 세트 점수: 0.762\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators' : [200,250,300,350,400],\n",
    "          'learning_rate' : [0.01,0.025,0.05,0.075,0.1,0.125],\n",
    "          'max_depth' : [5,7,10,13,15],\n",
    "          'num_leaves' : [35,37,40,42,45]}\n",
    "\n",
    "grid_search(LGBMClassifier(objective='multiclass', random_state=42, n_jobs=-1), params, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최상의 매개변수: {'num_leaves': 40, 'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.05}\n",
    "훈련 점수: 0.771\n",
    "테스트 세트 점수: 0.760"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10분 - 성능변화 크게 없음\n",
    "\n",
    "최상의 매개변수: {'num_leaves': 37, 'n_estimators': 300, 'max_depth': 13, 'learning_rate': 0.05}\n",
    "훈련 점수: 0.771\n",
    "테스트 세트 점수: 0.762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ss = pd.DataFrame(X_ss, columns=X.columns)\n",
    "y = pd.DataFrame(y)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "f1_macro_scores = []\n",
    "\n",
    "def skf_score(model):\n",
    "    for train_idx, valid_idx in skf.split(X_ss, y):\n",
    "        X_train = X_ss.iloc[train_idx]\n",
    "        X_val = y.iloc[train_idx]\n",
    "\n",
    "        y_train = X_ss.iloc[valid_idx]\n",
    "        y_val = y.iloc[valid_idx]\n",
    "\n",
    "        model.fit(X_train, X_val)\n",
    "\n",
    "        pred = model.predict(y_train)\n",
    "\n",
    "        f1_macro = f1_score(y_val, pred, average='macro')\n",
    "        f1_macro_scores.append(f1_macro)\n",
    "    \n",
    "    average_f1_macro = np.mean(f1_macro_scores)\n",
    "\n",
    "    print(\"Average F1-macro score:\", average_f1_macro)\n",
    "    try:\n",
    "        if model.feature_importances_.any():\n",
    "            feature_importances = model.feature_importances_\n",
    "            print(\"\\n\",'-'*10,'특성중요도','-'*10)\n",
    "            for feature, importance in zip(X_ss.columns, feature_importances):\n",
    "                print(f\"{feature}: {importance}\")\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-macro score: 0.7528012477225275\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "연간소득: 0.021138299394517394\n",
      "총상환원금: 0.08188699028073927\n",
      "총상환이자: 0.08633119073387403\n",
      "총상환원금+총상환이자: 0.017892359226226506\n",
      "총상환원금-총상환이자: 0.4859162479557219\n",
      "총상환원금*총상환이자: 0.017575779932279025\n",
      "총상환원금^2: 0.04432519658485146\n",
      "총상환이자^2: 0.1161858224054798\n",
      "sqrt(총상환원금): 0.06547769610864976\n",
      "sqrt(총상환이자): 0.06327041737766058\n"
     ]
    }
   ],
   "source": [
    "skf_score(DecisionTreeClassifier(min_samples_leaf=19, min_impurity_decrease=0, \n",
    "                                 max_features=0.68, max_depth=17, class_weight=None, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-macro score: 0.7764259953077468\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "연간소득: 0.06241124126952324\n",
      "총상환원금: 0.06494779137516525\n",
      "총상환이자: 0.09512233978565837\n",
      "총상환원금+총상환이자: 0.035440518664591615\n",
      "총상환원금-총상환이자: 0.38431213855745666\n",
      "총상환원금*총상환이자: 0.03356839455607797\n",
      "총상환원금^2: 0.06596673787971329\n",
      "총상환이자^2: 0.09566470653395252\n",
      "sqrt(총상환원금): 0.06631108900440655\n",
      "sqrt(총상환이자): 0.09625504237345472\n"
     ]
    }
   ],
   "source": [
    "skf_score(RandomForestClassifier(n_estimators=770, min_samples_leaf=1, min_impurity_decrease=0, \n",
    "                                 max_features=0.73, max_depth=95, random_state=42, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-macro score: 0.7772975157775472\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "연간소득: 0.03212502598762512\n",
      "총상환원금: 0.10362794995307922\n",
      "총상환이자: 0.25557741522789\n",
      "총상환원금+총상환이자: 0.08019416779279709\n",
      "총상환원금-총상환이자: 0.463946133852005\n",
      "총상환원금*총상환이자: 0.06452930718660355\n",
      "총상환원금^2: 0.0\n",
      "총상환이자^2: 0.0\n",
      "sqrt(총상환원금): 0.0\n",
      "sqrt(총상환이자): 0.0\n"
     ]
    }
   ],
   "source": [
    "skf_score(XGBClassifier(objective='multi:softmax', n_estimators=250, max_depth=90, \n",
    "          learning_rate=0.01, n_jobs=-1, random_state=42)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 81559, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744289\n",
      "[LightGBM] [Info] Start training from score -1.208056\n",
      "[LightGBM] [Info] Start training from score -1.248847\n",
      "[LightGBM] [Info] Start training from score -1.982382\n",
      "[LightGBM] [Info] Start training from score -2.564275\n",
      "[LightGBM] [Info] Start training from score -3.885514\n",
      "[LightGBM] [Info] Start training from score -5.434151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 81559, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744289\n",
      "[LightGBM] [Info] Start training from score -1.208056\n",
      "[LightGBM] [Info] Start training from score -1.248847\n",
      "[LightGBM] [Info] Start training from score -1.982382\n",
      "[LightGBM] [Info] Start training from score -2.564275\n",
      "[LightGBM] [Info] Start training from score -3.884917\n",
      "[LightGBM] [Info] Start training from score -5.436964\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208068\n",
      "[LightGBM] [Info] Start training from score -1.248859\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208068\n",
      "[LightGBM] [Info] Start training from score -1.248859\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744231\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982483\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744231\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982483\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208068\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.885526\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "Average F1-macro score: 0.7777161437855237\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "연간소득: 11460\n",
      "총상환원금: 9532\n",
      "총상환이자: 8395\n",
      "총상환원금+총상환이자: 6458\n",
      "총상환원금-총상환이자: 16508\n",
      "총상환원금*총상환이자: 5549\n",
      "총상환원금^2: 6510\n",
      "총상환이자^2: 4941\n",
      "sqrt(총상환원금): 3213\n",
      "sqrt(총상환이자): 3034\n"
     ]
    }
   ],
   "source": [
    "skf_score(LGBMClassifier(objective='multiclass', num_leaves=37, n_estimators=300, max_depth=13, \n",
    "               learning_rate=0.05, n_jobs=-1, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체적으로 \"총상환원금-총상환이자\" 의 특성 중요도가 가장 높게 나타났다.\n",
    "\n",
    "이는 상대적으로 낮은 대출등급에서 총상환원금보다 총상환이자가 더 많은 경우가 있기 때문에 음수가 생성되는데, 양/음수로 나뉘는 구간이 명확하기 때문이지 않을까 싶음\n",
    "\n",
    "model|k-Fold|Sk-Fold\n",
    "-|-|-\n",
    "DecisionTree Classifier|0.743|0.7528012477225275\n",
    "RandomForest Classifier|0.776|0.7764259953077468\n",
    "XGBoost Classifier|0.777|0.7772975157775472\n",
    "Light GBM Classifier|0.778|0.7777161437855237 --> 최고 성능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 앞에서 여러가지 모델링을 돌렸을 때 XGBoost에서 특이하게 대출기간에 대한 중요도가 엄청 크게 나타났다.\n",
    "\n",
    "### 이번에는 대출기간과 다른 컬럼을 이용하여 파생변수를 생성해서 성능을 확인해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 대출금액*대출기간\n",
    "2. 대출금액/대출기간\n",
    "3. 총상환원금*대출기간\n",
    "4. 총상환이자*대출기간\n",
    "5. 총상환원금/대출기간\n",
    "6. 총상환이자/대출기간\n",
    "\n",
    "총 6가지 파생변수를 생성\n",
    "\n",
    "대출금액, 대출기간, 총상환원금, 총상환이자 컬럼을 포함하여 10개의 Feature로 XGBoost 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>대출금액</th>\n",
       "      <th>대출기간</th>\n",
       "      <th>총상환원금</th>\n",
       "      <th>총상환이자</th>\n",
       "      <th>대출금액*대출기간</th>\n",
       "      <th>대출금액/대출기간</th>\n",
       "      <th>총상환원금*대출기간</th>\n",
       "      <th>총상환이자*대출기간</th>\n",
       "      <th>총상환원금/대출기간</th>\n",
       "      <th>총상환이자/대출기간</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90617</th>\n",
       "      <td>14400000</td>\n",
       "      <td>3</td>\n",
       "      <td>974580</td>\n",
       "      <td>492168.0</td>\n",
       "      <td>43200000</td>\n",
       "      <td>4800000.0</td>\n",
       "      <td>2923740</td>\n",
       "      <td>1476504.0</td>\n",
       "      <td>324860.0</td>\n",
       "      <td>164056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90618</th>\n",
       "      <td>28800000</td>\n",
       "      <td>5</td>\n",
       "      <td>583728</td>\n",
       "      <td>855084.0</td>\n",
       "      <td>144000000</td>\n",
       "      <td>5760000.0</td>\n",
       "      <td>2918640</td>\n",
       "      <td>4275420.0</td>\n",
       "      <td>116745.6</td>\n",
       "      <td>171016.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90619</th>\n",
       "      <td>14400000</td>\n",
       "      <td>3</td>\n",
       "      <td>1489128</td>\n",
       "      <td>241236.0</td>\n",
       "      <td>43200000</td>\n",
       "      <td>4800000.0</td>\n",
       "      <td>4467384</td>\n",
       "      <td>723708.0</td>\n",
       "      <td>496376.0</td>\n",
       "      <td>80412.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90620</th>\n",
       "      <td>15600000</td>\n",
       "      <td>3</td>\n",
       "      <td>1378368</td>\n",
       "      <td>818076.0</td>\n",
       "      <td>46800000</td>\n",
       "      <td>5200000.0</td>\n",
       "      <td>4135104</td>\n",
       "      <td>2454228.0</td>\n",
       "      <td>459456.0</td>\n",
       "      <td>272692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90621</th>\n",
       "      <td>8640000</td>\n",
       "      <td>3</td>\n",
       "      <td>596148</td>\n",
       "      <td>274956.0</td>\n",
       "      <td>25920000</td>\n",
       "      <td>2880000.0</td>\n",
       "      <td>1788444</td>\n",
       "      <td>824868.0</td>\n",
       "      <td>198716.0</td>\n",
       "      <td>91652.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           대출금액  대출기간    총상환원금     총상환이자  대출금액*대출기간  대출금액/대출기간  총상환원금*대출기간  \\\n",
       "90617  14400000     3   974580  492168.0   43200000  4800000.0     2923740   \n",
       "90618  28800000     5   583728  855084.0  144000000  5760000.0     2918640   \n",
       "90619  14400000     3  1489128  241236.0   43200000  4800000.0     4467384   \n",
       "90620  15600000     3  1378368  818076.0   46800000  5200000.0     4135104   \n",
       "90621   8640000     3   596148  274956.0   25920000  2880000.0     1788444   \n",
       "\n",
       "       총상환이자*대출기간  총상환원금/대출기간  총상환이자/대출기간  \n",
       "90617   1476504.0    324860.0    164056.0  \n",
       "90618   4275420.0    116745.6    171016.8  \n",
       "90619    723708.0    496376.0     80412.0  \n",
       "90620   2454228.0    459456.0    272692.0  \n",
       "90621    824868.0    198716.0     91652.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./train_new.csv')\n",
    "train.drop(['ID', '근로기간', '연간소득', '주택소유상태', '최근_2년간_연체_횟수', '부채_대비_소득_비율', '총계좌수', '대출목적', '총연체금액', '연체계좌수'], axis=1, inplace=True)\n",
    "train['대출금액*대출기간'] = train['대출금액'] * train['대출기간']\n",
    "train['대출금액/대출기간'] = train['대출금액'] / train['대출기간']\n",
    "train['총상환원금*대출기간'] = train['총상환원금'] * train['대출기간']\n",
    "train['총상환이자*대출기간'] = train['총상환이자'] * train['대출기간']\n",
    "train['총상환원금/대출기간'] = train['총상환원금'] / train['대출기간']\n",
    "train['총상환이자/대출기간'] = train['총상환이자'] / train['대출기간']\n",
    "train.loc[:, train.columns != '대출등급'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>대출금액</th>\n",
       "      <th>대출기간</th>\n",
       "      <th>총상환원금</th>\n",
       "      <th>총상환이자</th>\n",
       "      <th>대출금액*대출기간</th>\n",
       "      <th>대출금액/대출기간</th>\n",
       "      <th>총상환원금*대출기간</th>\n",
       "      <th>총상환이자*대출기간</th>\n",
       "      <th>총상환원금/대출기간</th>\n",
       "      <th>총상환이자/대출기간</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>90622.000000</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.856716e+07</td>\n",
       "      <td>3.676282</td>\n",
       "      <td>8.326632e+05</td>\n",
       "      <td>4.350762e+05</td>\n",
       "      <td>7.214806e+07</td>\n",
       "      <td>5.092617e+06</td>\n",
       "      <td>2.967748e+06</td>\n",
       "      <td>1.771490e+06</td>\n",
       "      <td>2.462372e+05</td>\n",
       "      <td>1.139413e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.035119e+07</td>\n",
       "      <td>0.946159</td>\n",
       "      <td>1.042279e+06</td>\n",
       "      <td>4.441826e+05</td>\n",
       "      <td>4.977547e+07</td>\n",
       "      <td>2.864262e+06</td>\n",
       "      <td>3.904647e+06</td>\n",
       "      <td>2.121681e+06</td>\n",
       "      <td>3.184181e+05</td>\n",
       "      <td>1.071500e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.600000e+06</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.080000e+07</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.126420e+05</td>\n",
       "      <td>1.378470e+05</td>\n",
       "      <td>3.240000e+07</td>\n",
       "      <td>3.000000e+06</td>\n",
       "      <td>1.131960e+06</td>\n",
       "      <td>4.286160e+05</td>\n",
       "      <td>8.431080e+04</td>\n",
       "      <td>4.112160e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.728000e+07</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.047280e+05</td>\n",
       "      <td>2.934180e+05</td>\n",
       "      <td>6.048000e+07</td>\n",
       "      <td>4.400000e+06</td>\n",
       "      <td>2.198700e+06</td>\n",
       "      <td>9.999360e+05</td>\n",
       "      <td>1.663848e+05</td>\n",
       "      <td>8.382800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.448000e+07</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.067496e+06</td>\n",
       "      <td>5.794080e+05</td>\n",
       "      <td>1.008000e+08</td>\n",
       "      <td>6.400000e+06</td>\n",
       "      <td>3.977040e+06</td>\n",
       "      <td>2.303235e+06</td>\n",
       "      <td>3.012320e+05</td>\n",
       "      <td>1.527040e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.200000e+07</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.195594e+07</td>\n",
       "      <td>5.653416e+06</td>\n",
       "      <td>2.100000e+08</td>\n",
       "      <td>1.400000e+07</td>\n",
       "      <td>1.989695e+08</td>\n",
       "      <td>2.826708e+07</td>\n",
       "      <td>1.398531e+07</td>\n",
       "      <td>1.349580e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               대출금액          대출기간         총상환원금         총상환이자     대출금액*대출기간  \\\n",
       "count  9.062200e+04  90622.000000  9.062200e+04  9.062200e+04  9.062200e+04   \n",
       "mean   1.856716e+07      3.676282  8.326632e+05  4.350762e+05  7.214806e+07   \n",
       "std    1.035119e+07      0.946159  1.042279e+06  4.441826e+05  4.977547e+07   \n",
       "min    1.200000e+06      3.000000  0.000000e+00  0.000000e+00  3.600000e+06   \n",
       "25%    1.080000e+07      3.000000  3.126420e+05  1.378470e+05  3.240000e+07   \n",
       "50%    1.728000e+07      3.000000  6.047280e+05  2.934180e+05  6.048000e+07   \n",
       "75%    2.448000e+07      5.000000  1.067496e+06  5.794080e+05  1.008000e+08   \n",
       "max    4.200000e+07      5.000000  4.195594e+07  5.653416e+06  2.100000e+08   \n",
       "\n",
       "          대출금액/대출기간    총상환원금*대출기간    총상환이자*대출기간    총상환원금/대출기간    총상환이자/대출기간  \n",
       "count  9.062200e+04  9.062200e+04  9.062200e+04  9.062200e+04  9.062200e+04  \n",
       "mean   5.092617e+06  2.967748e+06  1.771490e+06  2.462372e+05  1.139413e+05  \n",
       "std    2.864262e+06  3.904647e+06  2.121681e+06  3.184181e+05  1.071500e+05  \n",
       "min    4.000000e+05  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "25%    3.000000e+06  1.131960e+06  4.286160e+05  8.431080e+04  4.112160e+04  \n",
       "50%    4.400000e+06  2.198700e+06  9.999360e+05  1.663848e+05  8.382800e+04  \n",
       "75%    6.400000e+06  3.977040e+06  2.303235e+06  3.012320e+05  1.527040e+05  \n",
       "max    1.400000e+07  1.989695e+08  2.826708e+07  1.398531e+07  1.349580e+06  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "train['대출등급'] = le.fit_transform(train['대출등급'])\n",
    "\n",
    "X = train.loc[:, train.columns != '대출등급']\n",
    "y = train.loc[:, '대출등급']\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_ss = ss.fit_transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_ss, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'min_samples_leaf': 19, 'min_impurity_decrease': 0.0, 'max_features': 0.68, 'max_depth': 17, 'class_weight': None}\n",
      "훈련 점수: 0.757\n",
      "테스트 세트 점수: 0.773\n"
     ]
    }
   ],
   "source": [
    "params = {'min_samples_leaf':[18,19,20,21,22],\n",
    "          'min_impurity_decrease':[0.0],\n",
    "          'max_features':['auto',0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.69,0.70],\n",
    "          'max_depth':[None,11,12,13,14,15,16,17,18],\n",
    "          'class_weight' : [None, 'balanced']}\n",
    "\n",
    "grid_search(DecisionTreeClassifier(random_state=42), params, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'n_estimators': 770, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_features': 0.73, 'max_depth': 95}\n",
      "훈련 점수: 0.831\n",
      "테스트 세트 점수: 0.830\n"
     ]
    }
   ],
   "source": [
    "params = {'min_samples_leaf':[1,3,5],\n",
    "          'min_impurity_decrease':[0.0],\n",
    "          'max_features':[0.71,0.73,0.75],\n",
    "          'max_depth':[91,93,95,97,99],\n",
    "          'n_estimators' : [750,770,790,810,830,850]}\n",
    "\n",
    "grid_search(RandomForestClassifier(n_jobs=-1, random_state=42), params, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "92분소요... 후행 작업 중단\n",
    "\n",
    "최상의 매개변수: {'n_estimators': 770, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_features': 0.73, 'max_depth': 95}\n",
    "훈련 점수: 0.831\n",
    "테스트 세트 점수: 0.830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'objective': 'multi:softmax', 'n_estimators': 500, 'max_depth': 15, 'learning_rate': 0.3}\n",
      "훈련 점수: 0.830\n",
      "테스트 세트 점수: 0.830\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators' : [500,700,850,1000],\n",
    "          'learning_rate' : [0.01,0.05,0.1,0.2,0.3,0.4],\n",
    "          'max_depth' : [5,10,15,20,25,30,35,40],\n",
    "          'objective' : ['multi:softmax']}\n",
    "\n",
    "grid_search(XGBClassifier(random_state=42, n_jobs=-1), params, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최상의 매개변수: {'objective': 'multi:softmax', 'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.2}\n",
    "훈련 점수: 0.832\n",
    "테스트 세트 점수: 0.831"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "55분 소요.. 성능변화 크게 없음\n",
    "\n",
    "최상의 매개변수: {'objective': 'multi:softmax', 'n_estimators': 500, 'max_depth': 15, 'learning_rate': 0.3}\n",
    "훈련 점수: 0.830\n",
    "테스트 세트 점수: 0.830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2298\n",
      "[LightGBM] [Info] Number of data points in the train set: 63435, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744243\n",
      "[LightGBM] [Info] Start training from score -1.208106\n",
      "[LightGBM] [Info] Start training from score -1.248814\n",
      "[LightGBM] [Info] Start training from score -1.982449\n",
      "[LightGBM] [Info] Start training from score -2.564256\n",
      "[LightGBM] [Info] Start training from score -3.885346\n",
      "[LightGBM] [Info] Start training from score -5.433754\n",
      "최상의 매개변수: {'num_leaves': 25, 'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.1}\n",
      "훈련 점수: 0.821\n",
      "테스트 세트 점수: 0.819\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators' : [400,500,600,800,1000],\n",
    "          'learning_rate' : [0.001,0.005,0.01,0.05,0.1,0.2],\n",
    "          'max_depth' : [5,10,15,20,25,30],\n",
    "          'num_leaves' : [20,25,30,35,40]}\n",
    "\n",
    "grid_search(LGBMClassifier(objective='multiclass', random_state=42, n_jobs=-1), params, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최상의 매개변수: {'num_leaves': 25, 'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.1}\n",
    "훈련 점수: 0.821\n",
    "테스트 세트 점수: 0.819"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80분 소요... 후행 작업 중단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ss = pd.DataFrame(X_ss, columns=X.columns)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-macro score: 0.7803377111430769\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "대출기간: 0.020414716670254046\n",
      "총상환원금: 0.058643291827882964\n",
      "총상환이자: 0.11157762561254556\n",
      "총상환원금*대출기간: 0.06780954164453884\n",
      "총상환이자*대출기간: 0.11871771357899652\n",
      "총상환원금/대출기간: 0.05714950767932168\n",
      "총상환이자/대출기간: 0.11910432089473721\n",
      "총상환원금-총상환이자: 0.4465832820917232\n"
     ]
    }
   ],
   "source": [
    "skf_score(DecisionTreeClassifier(min_samples_leaf=19, min_impurity_decrease=0, \n",
    "                                 max_features=0.68, max_depth=17, class_weight=None, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-macro score: 0.8454329888401269\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "대출금액: 0.02905751461041064\n",
      "대출기간: 0.025428606055366614\n",
      "총상환원금: 0.1479504335018489\n",
      "총상환이자: 0.13901697289703976\n",
      "대출금액*대출기간: 0.029655404271213263\n",
      "대출금액/대출기간: 0.02966126849103156\n",
      "총상환원금*대출기간: 0.1718265561943464\n",
      "총상환이자*대출기간: 0.1398371559565516\n",
      "총상환원금/대출기간: 0.14731120258071137\n",
      "총상환이자/대출기간: 0.1402548854414799\n"
     ]
    }
   ],
   "source": [
    "skf_score(RandomForestClassifier(n_estimators=770, min_samples_leaf=1, min_impurity_decrease=0, \n",
    "                                 max_features=0.73, max_depth=95, random_state=42, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-macro score: 0.8344399032633336\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "대출금액: 0.006457563955336809\n",
      "대출기간: 0.7597364783287048\n",
      "총상환원금: 0.025837700814008713\n",
      "총상환이자: 0.02248673141002655\n",
      "대출금액*대출기간: 0.004607027862221003\n",
      "대출금액/대출기간: 0.004678612109273672\n",
      "총상환원금*대출기간: 0.03731198608875275\n",
      "총상환이자*대출기간: 0.055219151079654694\n",
      "총상환원금/대출기간: 0.03926330432295799\n",
      "총상환이자/대출기간: 0.04440142214298248\n"
     ]
    }
   ],
   "source": [
    "skf_score(XGBClassifier(objective='multi:softmax', n_estimators=500, max_depth=10, \n",
    "          learning_rate=0.2, n_jobs=-1, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2298\n",
      "[LightGBM] [Info] Number of data points in the train set: 81559, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744289\n",
      "[LightGBM] [Info] Start training from score -1.208056\n",
      "[LightGBM] [Info] Start training from score -1.248847\n",
      "[LightGBM] [Info] Start training from score -1.982382\n",
      "[LightGBM] [Info] Start training from score -2.564275\n",
      "[LightGBM] [Info] Start training from score -3.885514\n",
      "[LightGBM] [Info] Start training from score -5.434151\n",
      "[LightGBM] [Info] Total Bins 2298\n",
      "[LightGBM] [Info] Number of data points in the train set: 81559, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744289\n",
      "[LightGBM] [Info] Start training from score -1.208056\n",
      "[LightGBM] [Info] Start training from score -1.248847\n",
      "[LightGBM] [Info] Start training from score -1.982382\n",
      "[LightGBM] [Info] Start training from score -2.564275\n",
      "[LightGBM] [Info] Start training from score -3.884917\n",
      "[LightGBM] [Info] Start training from score -5.436964\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 2298\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208068\n",
      "[LightGBM] [Info] Start training from score -1.248859\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 2298\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208068\n",
      "[LightGBM] [Info] Start training from score -1.248859\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 2298\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 2298\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Info] Total Bins 2298\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 2298\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744231\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982483\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 2298\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744231\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982483\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 2298\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208068\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.885526\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Average F1-macro score: 0.8050474063923861\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "대출금액: 12606\n",
      "대출기간: 227\n",
      "총상환원금: 13839\n",
      "총상환이자: 11121\n",
      "대출금액*대출기간: 4237\n",
      "대출금액/대출기간: 5880\n",
      "총상환원금*대출기간: 11271\n",
      "총상환이자*대출기간: 7340\n",
      "총상환원금/대출기간: 7469\n",
      "총상환이자/대출기간: 9602\n"
     ]
    }
   ],
   "source": [
    "skf_score(LGBMClassifier(objective='multiclass', num_leaves=25, n_estimators=500, max_depth=10, \n",
    "               learning_rate=0.1, n_jobs=-1, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model|k-Fold|Sk-Fold\n",
    "-|-|-\n",
    "DecisionTree Classifier|0.773|0.7803377111430769\n",
    "RandomForest Classifier|0.830|0.8454329888401269 --> 최고 성능\n",
    "XGBoost Classifier|0.830|0.8344399032633336 \n",
    "Light GBM Classifier|0.819|0.8050474063923861\n",
    "\n",
    "확실히 XGB에서 대출기간에서 영향을 많이 받는 모습을 볼 수 있음 (특성 중요도 76%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이번에는 위 모델링 결과에서 영향력이 작은 대출금액, 대출금액*대출기간, 대출금액/대출기간 3개 컬럼을 제거하고\n",
    "\n",
    "### 앞서 높은 특성중요도를 보였던 총상환원금 - 총상환이자 컬럼을 추가하여 재모델링 (총 8개 컬럼 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>대출기간</th>\n",
       "      <th>총상환원금</th>\n",
       "      <th>총상환이자</th>\n",
       "      <th>대출등급</th>\n",
       "      <th>총상환원금*대출기간</th>\n",
       "      <th>총상환이자*대출기간</th>\n",
       "      <th>총상환원금/대출기간</th>\n",
       "      <th>총상환이자/대출기간</th>\n",
       "      <th>총상환원금-총상환이자</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>373572</td>\n",
       "      <td>234060.0</td>\n",
       "      <td>B</td>\n",
       "      <td>1867860</td>\n",
       "      <td>1170300.0</td>\n",
       "      <td>74714.4</td>\n",
       "      <td>46812.0</td>\n",
       "      <td>139512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>928644</td>\n",
       "      <td>151944.0</td>\n",
       "      <td>A</td>\n",
       "      <td>2785932</td>\n",
       "      <td>455832.0</td>\n",
       "      <td>309548.0</td>\n",
       "      <td>50648.0</td>\n",
       "      <td>776700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>325824</td>\n",
       "      <td>153108.0</td>\n",
       "      <td>C</td>\n",
       "      <td>977472</td>\n",
       "      <td>459324.0</td>\n",
       "      <td>108608.0</td>\n",
       "      <td>51036.0</td>\n",
       "      <td>172716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>240216</td>\n",
       "      <td>55428.0</td>\n",
       "      <td>A</td>\n",
       "      <td>720648</td>\n",
       "      <td>166284.0</td>\n",
       "      <td>80072.0</td>\n",
       "      <td>18476.0</td>\n",
       "      <td>184788.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   대출기간   총상환원금     총상환이자 대출등급  총상환원금*대출기간  총상환이자*대출기간  총상환원금/대출기간  \\\n",
       "0     3       0       0.0    C           0         0.0         0.0   \n",
       "1     5  373572  234060.0    B     1867860   1170300.0     74714.4   \n",
       "2     3  928644  151944.0    A     2785932    455832.0    309548.0   \n",
       "3     3  325824  153108.0    C      977472    459324.0    108608.0   \n",
       "4     3  240216   55428.0    A      720648    166284.0     80072.0   \n",
       "\n",
       "   총상환이자/대출기간  총상환원금-총상환이자  \n",
       "0         0.0          0.0  \n",
       "1     46812.0     139512.0  \n",
       "2     50648.0     776700.0  \n",
       "3     51036.0     172716.0  \n",
       "4     18476.0     184788.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./train_new.csv')\n",
    "train.drop(['ID', '대출금액', '근로기간', '연간소득', '주택소유상태', '최근_2년간_연체_횟수', '부채_대비_소득_비율', '총계좌수', '대출목적', '총연체금액', '연체계좌수'], axis=1, inplace=True)\n",
    "train['총상환원금*대출기간'] = train['총상환원금'] * train['대출기간']\n",
    "train['총상환이자*대출기간'] = train['총상환이자'] * train['대출기간']\n",
    "train['총상환원금/대출기간'] = train['총상환원금'] / train['대출기간']\n",
    "train['총상환이자/대출기간'] = train['총상환이자'] / train['대출기간']\n",
    "train['총상환원금-총상환이자'] = train['총상환원금'] - train['총상환이자']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>대출기간</th>\n",
       "      <th>총상환원금</th>\n",
       "      <th>총상환이자</th>\n",
       "      <th>총상환원금*대출기간</th>\n",
       "      <th>총상환이자*대출기간</th>\n",
       "      <th>총상환원금/대출기간</th>\n",
       "      <th>총상환이자/대출기간</th>\n",
       "      <th>총상환원금-총상환이자</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>90622.000000</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "      <td>9.062200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.676282</td>\n",
       "      <td>8.326632e+05</td>\n",
       "      <td>4.350762e+05</td>\n",
       "      <td>2.967748e+06</td>\n",
       "      <td>1.771490e+06</td>\n",
       "      <td>2.462372e+05</td>\n",
       "      <td>1.139413e+05</td>\n",
       "      <td>3.975871e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.946159</td>\n",
       "      <td>1.042279e+06</td>\n",
       "      <td>4.441826e+05</td>\n",
       "      <td>3.904647e+06</td>\n",
       "      <td>2.121681e+06</td>\n",
       "      <td>3.184181e+05</td>\n",
       "      <td>1.071500e+05</td>\n",
       "      <td>9.521424e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.032960e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.126420e+05</td>\n",
       "      <td>1.378470e+05</td>\n",
       "      <td>1.131960e+06</td>\n",
       "      <td>4.286160e+05</td>\n",
       "      <td>8.431080e+04</td>\n",
       "      <td>4.112160e+04</td>\n",
       "      <td>3.764400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.047280e+05</td>\n",
       "      <td>2.934180e+05</td>\n",
       "      <td>2.198700e+06</td>\n",
       "      <td>9.999360e+05</td>\n",
       "      <td>1.663848e+05</td>\n",
       "      <td>8.382800e+04</td>\n",
       "      <td>2.324520e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.067496e+06</td>\n",
       "      <td>5.794080e+05</td>\n",
       "      <td>3.977040e+06</td>\n",
       "      <td>2.303235e+06</td>\n",
       "      <td>3.012320e+05</td>\n",
       "      <td>1.527040e+05</td>\n",
       "      <td>5.644650e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.195594e+07</td>\n",
       "      <td>5.653416e+06</td>\n",
       "      <td>1.989695e+08</td>\n",
       "      <td>2.826708e+07</td>\n",
       "      <td>1.398531e+07</td>\n",
       "      <td>1.349580e+06</td>\n",
       "      <td>4.157404e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               대출기간         총상환원금         총상환이자    총상환원금*대출기간    총상환이자*대출기간  \\\n",
       "count  90622.000000  9.062200e+04  9.062200e+04  9.062200e+04  9.062200e+04   \n",
       "mean       3.676282  8.326632e+05  4.350762e+05  2.967748e+06  1.771490e+06   \n",
       "std        0.946159  1.042279e+06  4.441826e+05  3.904647e+06  2.121681e+06   \n",
       "min        3.000000  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%        3.000000  3.126420e+05  1.378470e+05  1.131960e+06  4.286160e+05   \n",
       "50%        3.000000  6.047280e+05  2.934180e+05  2.198700e+06  9.999360e+05   \n",
       "75%        5.000000  1.067496e+06  5.794080e+05  3.977040e+06  2.303235e+06   \n",
       "max        5.000000  4.195594e+07  5.653416e+06  1.989695e+08  2.826708e+07   \n",
       "\n",
       "         총상환원금/대출기간    총상환이자/대출기간   총상환원금-총상환이자  \n",
       "count  9.062200e+04  9.062200e+04  9.062200e+04  \n",
       "mean   2.462372e+05  1.139413e+05  3.975871e+05  \n",
       "std    3.184181e+05  1.071500e+05  9.521424e+05  \n",
       "min    0.000000e+00  0.000000e+00 -4.032960e+06  \n",
       "25%    8.431080e+04  4.112160e+04  3.764400e+04  \n",
       "50%    1.663848e+05  8.382800e+04  2.324520e+05  \n",
       "75%    3.012320e+05  1.527040e+05  5.644650e+05  \n",
       "max    1.398531e+07  1.349580e+06  4.157404e+07  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "train['대출등급'] = le.fit_transform(train['대출등급'])\n",
    "\n",
    "X = train.loc[:, train.columns != '대출등급']\n",
    "y = train.loc[:, '대출등급']\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_ss = ss.fit_transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_ss, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'min_samples_leaf': 18, 'min_impurity_decrease': 0.0, 'max_features': 0.65, 'max_depth': 15, 'class_weight': None}\n",
      "훈련 점수: 0.781\n",
      "테스트 세트 점수: 0.768\n"
     ]
    }
   ],
   "source": [
    "params = {'min_samples_leaf':[18,19,20,21,22],\n",
    "          'min_impurity_decrease':[0.0],\n",
    "          'max_features':['auto',0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.69,0.70],\n",
    "          'max_depth':[None,11,12,13,14,15,16,17,18],\n",
    "          'class_weight' : [None, 'balanced']}\n",
    "\n",
    "grid_search(DecisionTreeClassifier(random_state=42), params, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'n_estimators': 850, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0, 'max_features': 0.73, 'max_depth': 95}\n",
      "훈련 점수: 0.831\n",
      "테스트 세트 점수: 0.829\n"
     ]
    }
   ],
   "source": [
    "params = {'min_samples_leaf':[1,3,5],\n",
    "          'min_impurity_decrease':[0.0],\n",
    "          'max_features':[0.71,0.73,0.75],\n",
    "          'max_depth':[91,93,95,97,99],\n",
    "          'n_estimators' : [750,770,790,810,830,850]}\n",
    "\n",
    "grid_search(RandomForestClassifier(n_jobs=-1, random_state=42), params, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "95분.. 후행 작업 중단\n",
    "\n",
    "최상의 매개변수: {'n_estimators': 850, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0, 'max_features': 0.73, 'max_depth': 95}\n",
    "훈련 점수: 0.831\n",
    "테스트 세트 점수: 0.829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 매개변수: {'objective': 'multi:softmax', 'n_estimators': 150, 'max_depth': 100, 'learning_rate': 0.01}\n",
      "훈련 점수: 0.817\n",
      "테스트 세트 점수: 0.813\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators' : [150,300,500,1000],\n",
    "          'learning_rate' : [0.001,0.01,0.1],\n",
    "          'max_depth' : [50,100,150],\n",
    "          'objective' : ['multi:softmax']}\n",
    "\n",
    "grid_search(XGBClassifier(random_state=42, n_jobs=-1), params, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB 튜닝 이력 (1번당 평균 10~15분 소요)\n",
    "\n",
    "첫 번쨰 랜덤서치 사용 이후 그리드서치..를 사용하려 했으나 역시나 시간이 1시간반 이상 소요되어 랜덤서치로 쭉 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최상의 매개변수: {'objective': 'multi:softmax', 'n_estimators': 200, 'max_depth': 100, 'learning_rate': 0.01}\n",
    "훈련 점수: 0.815\n",
    "테스트 세트 점수: 0.814"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최상의 매개변수: {'objective': 'multi:softmax', 'n_estimators': 150, 'max_depth': 90, 'learning_rate': 0.01}\n",
    "훈련 점수: 0.817\n",
    "테스트 세트 점수: 0.813"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최상의 매개변수: {'objective': 'multi:softmax', 'n_estimators': 130, 'max_depth': 100, 'learning_rate': 0.01}\n",
    "훈련 점수: 0.816\n",
    "테스트 세트 점수: 0.813"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세번정도 미세 튜닝결과 성능이 크게 나아지는 부분이 없어서 2번째 결과를 사용\n",
    "\n",
    "혹시 몰라 큰 값도 잡아봤는데, 두번째 결과가 여전히 최상의 매개변수로 출력됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1788\n",
      "[LightGBM] [Info] Number of data points in the train set: 63435, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.744243\n",
      "[LightGBM] [Info] Start training from score -1.208106\n",
      "[LightGBM] [Info] Start training from score -1.248814\n",
      "[LightGBM] [Info] Start training from score -1.982449\n",
      "[LightGBM] [Info] Start training from score -2.564256\n",
      "[LightGBM] [Info] Start training from score -3.885346\n",
      "[LightGBM] [Info] Start training from score -5.433754\n",
      "최상의 매개변수: {'num_leaves': 30, 'n_estimators': 500, 'max_depth': 125, 'learning_rate': 0.05}\n",
      "훈련 점수: 0.809\n",
      "테스트 세트 점수: 0.799\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators' : [450,500,550,600],\n",
    "          'learning_rate' : [0.01,0.05,0.1,0.2,0.3,0.4],\n",
    "          'max_depth' : [75,100,125,150],\n",
    "          'num_leaves' : [20,25,30]}\n",
    "\n",
    "grid_search(LGBMClassifier(objective='multiclass', random_state=42, n_jobs=-1), params, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ss = pd.DataFrame(X_ss, columns=X.columns)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-macro score: 0.7825190595974667\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "대출기간: 0.03252951874349846\n",
      "총상환원금: 0.07039780582122465\n",
      "총상환이자: 0.1384651286046061\n",
      "총상환원금*대출기간: 0.04919493517081665\n",
      "총상환이자*대출기간: 0.17311708469403161\n",
      "총상환원금/대출기간: 0.04320628644937883\n",
      "총상환이자/대출기간: 0.05408595922536836\n",
      "총상환원금-총상환이자: 0.4390032812910753\n"
     ]
    }
   ],
   "source": [
    "skf_score(DecisionTreeClassifier(min_samples_leaf=18, min_impurity_decrease=0, \n",
    "                                 max_features=0.65, max_depth=15, class_weight=None, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-macro score: 0.8410873545863643\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "대출기간: 0.024334394715308655\n",
      "총상환원금: 0.07112992841695093\n",
      "총상환이자: 0.10338090169824544\n",
      "총상환원금*대출기간: 0.08933986188326175\n",
      "총상환이자*대출기간: 0.11699873373477396\n",
      "총상환원금/대출기간: 0.06998909211801188\n",
      "총상환이자/대출기간: 0.12577413064420231\n",
      "총상환원금-총상환이자: 0.3990529567892452\n"
     ]
    }
   ],
   "source": [
    "skf_score(RandomForestClassifier(n_estimators=850, min_samples_leaf=3, min_impurity_decrease=0, \n",
    "                                 max_features=0.73, max_depth=95, random_state=42, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-macro score: 0.8204524829028639\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "대출기간: 0.3718532621860504\n",
      "총상환원금: 0.025181423872709274\n",
      "총상환이자: 0.03701609745621681\n",
      "총상환원금*대출기간: 0.0464862585067749\n",
      "총상환이자*대출기간: 0.10007234662771225\n",
      "총상환원금/대출기간: 0.05068105086684227\n",
      "총상환이자/대출기간: 0.15467771887779236\n",
      "총상환원금-총상환이자: 0.21403177082538605\n"
     ]
    }
   ],
   "source": [
    "skf_score(XGBClassifier(objective='multi:softmax', n_estimators=150, max_depth=100, \n",
    "          learning_rate=0.01, n_jobs=-1, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Info] Total Bins 1788\n",
      "[LightGBM] [Info] Number of data points in the train set: 81559, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.744289\n",
      "[LightGBM] [Info] Start training from score -1.208056\n",
      "[LightGBM] [Info] Start training from score -1.248847\n",
      "[LightGBM] [Info] Start training from score -1.982382\n",
      "[LightGBM] [Info] Start training from score -2.564275\n",
      "[LightGBM] [Info] Start training from score -3.885514\n",
      "[LightGBM] [Info] Start training from score -5.434151\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1788\n",
      "[LightGBM] [Info] Number of data points in the train set: 81559, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.744289\n",
      "[LightGBM] [Info] Start training from score -1.208056\n",
      "[LightGBM] [Info] Start training from score -1.248847\n",
      "[LightGBM] [Info] Start training from score -1.982382\n",
      "[LightGBM] [Info] Start training from score -2.564275\n",
      "[LightGBM] [Info] Start training from score -3.884917\n",
      "[LightGBM] [Info] Start training from score -5.436964\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1788\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208068\n",
      "[LightGBM] [Info] Start training from score -1.248859\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1788\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208068\n",
      "[LightGBM] [Info] Start training from score -1.248859\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1788\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1788\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564128\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.436976\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1788\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1788\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.744231\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982483\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1788\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.744231\n",
      "[LightGBM] [Info] Start training from score -1.208109\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982483\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.884929\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1788\n",
      "[LightGBM] [Info] Number of data points in the train set: 81560, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.744301\n",
      "[LightGBM] [Info] Start training from score -1.208068\n",
      "[LightGBM] [Info] Start training from score -1.248817\n",
      "[LightGBM] [Info] Start training from score -1.982394\n",
      "[LightGBM] [Info] Start training from score -2.564287\n",
      "[LightGBM] [Info] Start training from score -3.885526\n",
      "[LightGBM] [Info] Start training from score -5.434163\n",
      "Average F1-macro score: 0.8332265359229514\n",
      "\n",
      " ---------- 특성중요도 ----------\n",
      "대출기간: 1056\n",
      "총상환원금: 16616\n",
      "총상환이자: 15189\n",
      "총상환원금*대출기간: 14831\n",
      "총상환이자*대출기간: 8733\n",
      "총상환원금/대출기간: 11425\n",
      "총상환이자/대출기간: 14085\n",
      "총상환원금-총상환이자: 19565\n"
     ]
    }
   ],
   "source": [
    "skf_score(LGBMClassifier(objective='multiclass', num_leaves=30, n_estimators=500, max_depth=125, \n",
    "               learning_rate=0.05, n_jobs=-1 , random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model|k-Fold|Sk-Fold\n",
    "-|-|-\n",
    "DecisionTree Classifier|0.768|0.7825190595974667\n",
    "RandomForest Classifier|0.829|0.8410873545863643 --> 최고 성능\n",
    "XGBoost Classifier|0.813|0.8204524829028639\n",
    "Light GBM Classifier|0.799|0.8332265359229514"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
